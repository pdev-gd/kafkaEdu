[2022-12-08 11:08:44,749] INFO WorkerInfo values: 
	jvm.args = -Xms256M, -Xmx2G, -XX:+UseG1GC, -XX:MaxGCPauseMillis=20, -XX:InitiatingHeapOccupancyPercent=35, -XX:+ExplicitGCInvokesConcurrent, -XX:MaxInlineLevel=15, -Djava.awt.headless=true, -Dcom.sun.management.jmxremote, -Dcom.sun.management.jmxremote.authenticate=false, -Dcom.sun.management.jmxremote.ssl=false, -Dkafka.logs.dir=/Users/byoon/study/kafka/Test02/kafka_client_2.8.2//bin/../logs, -Dlog4j.configuration=file:/Users/byoon/study/kafka/Test02/kafka_client_2.8.2//bin/../config/connect-log4j.properties
	jvm.spec = Oracle Corporation, Java HotSpot(TM) 64-Bit Server VM, 1.8.0_152, 25.152-b16
	jvm.classpath = /Users/byoon/study/kafka/Test02/kafka_client_2.8.2//bin/../libs/activation-1.1.1.jar:/Users/byoon/study/kafka/Test02/kafka_client_2.8.2//bin/../libs/aopalliance-repackaged-2.6.1.jar:/Users/byoon/study/kafka/Test02/kafka_client_2.8.2//bin/../libs/argparse4j-0.7.0.jar:/Users/byoon/study/kafka/Test02/kafka_client_2.8.2//bin/../libs/audience-annotations-0.5.0.jar:/Users/byoon/study/kafka/Test02/kafka_client_2.8.2//bin/../libs/commons-cli-1.4.jar:/Users/byoon/study/kafka/Test02/kafka_client_2.8.2//bin/../libs/commons-lang3-3.8.1.jar:/Users/byoon/study/kafka/Test02/kafka_client_2.8.2//bin/../libs/connect-api-2.8.2.jar:/Users/byoon/study/kafka/Test02/kafka_client_2.8.2//bin/../libs/connect-basic-auth-extension-2.8.2.jar:/Users/byoon/study/kafka/Test02/kafka_client_2.8.2//bin/../libs/connect-file-2.8.2.jar:/Users/byoon/study/kafka/Test02/kafka_client_2.8.2//bin/../libs/connect-json-2.8.2.jar:/Users/byoon/study/kafka/Test02/kafka_client_2.8.2//bin/../libs/connect-mirror-2.8.2.jar:/Users/byoon/study/kafka/Test02/kafka_client_2.8.2//bin/../libs/connect-mirror-client-2.8.2.jar:/Users/byoon/study/kafka/Test02/kafka_client_2.8.2//bin/../libs/connect-runtime-2.8.2.jar:/Users/byoon/study/kafka/Test02/kafka_client_2.8.2//bin/../libs/connect-transforms-2.8.2.jar:/Users/byoon/study/kafka/Test02/kafka_client_2.8.2//bin/../libs/hk2-api-2.6.1.jar:/Users/byoon/study/kafka/Test02/kafka_client_2.8.2//bin/../libs/hk2-locator-2.6.1.jar:/Users/byoon/study/kafka/Test02/kafka_client_2.8.2//bin/../libs/hk2-utils-2.6.1.jar:/Users/byoon/study/kafka/Test02/kafka_client_2.8.2//bin/../libs/jackson-annotations-2.10.5.jar:/Users/byoon/study/kafka/Test02/kafka_client_2.8.2//bin/../libs/jackson-core-2.10.5.jar:/Users/byoon/study/kafka/Test02/kafka_client_2.8.2//bin/../libs/jackson-databind-2.10.5.1.jar:/Users/byoon/study/kafka/Test02/kafka_client_2.8.2//bin/../libs/jackson-dataformat-csv-2.10.5.jar:/Users/byoon/study/kafka/Test02/kafka_client_2.8.2//bin/../libs/jackson-datatype-jdk8-2.10.5.jar:/Users/byoon/study/kafka/Test02/kafka_client_2.8.2//bin/../libs/jackson-jaxrs-base-2.10.5.jar:/Users/byoon/study/kafka/Test02/kafka_client_2.8.2//bin/../libs/jackson-jaxrs-json-provider-2.10.5.jar:/Users/byoon/study/kafka/Test02/kafka_client_2.8.2//bin/../libs/jackson-module-jaxb-annotations-2.10.5.jar:/Users/byoon/study/kafka/Test02/kafka_client_2.8.2//bin/../libs/jackson-module-paranamer-2.10.5.jar:/Users/byoon/study/kafka/Test02/kafka_client_2.8.2//bin/../libs/jackson-module-scala_2.13-2.10.5.jar:/Users/byoon/study/kafka/Test02/kafka_client_2.8.2//bin/../libs/jakarta.activation-api-1.2.1.jar:/Users/byoon/study/kafka/Test02/kafka_client_2.8.2//bin/../libs/jakarta.annotation-api-1.3.5.jar:/Users/byoon/study/kafka/Test02/kafka_client_2.8.2//bin/../libs/jakarta.inject-2.6.1.jar:/Users/byoon/study/kafka/Test02/kafka_client_2.8.2//bin/../libs/jakarta.validation-api-2.0.2.jar:/Users/byoon/study/kafka/Test02/kafka_client_2.8.2//bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/Users/byoon/study/kafka/Test02/kafka_client_2.8.2//bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/Users/byoon/study/kafka/Test02/kafka_client_2.8.2//bin/../libs/javassist-3.27.0-GA.jar:/Users/byoon/study/kafka/Test02/kafka_client_2.8.2//bin/../libs/javax.servlet-api-3.1.0.jar:/Users/byoon/study/kafka/Test02/kafka_client_2.8.2//bin/../libs/javax.ws.rs-api-2.1.1.jar:/Users/byoon/study/kafka/Test02/kafka_client_2.8.2//bin/../libs/jaxb-api-2.3.0.jar:/Users/byoon/study/kafka/Test02/kafka_client_2.8.2//bin/../libs/jersey-client-2.34.jar:/Users/byoon/study/kafka/Test02/kafka_client_2.8.2//bin/../libs/jersey-common-2.34.jar:/Users/byoon/study/kafka/Test02/kafka_client_2.8.2//bin/../libs/jersey-container-servlet-2.34.jar:/Users/byoon/study/kafka/Test02/kafka_client_2.8.2//bin/../libs/jersey-container-servlet-core-2.34.jar:/Users/byoon/study/kafka/Test02/kafka_client_2.8.2//bin/../libs/jersey-hk2-2.34.jar:/Users/byoon/study/kafka/Test02/kafka_client_2.8.2//bin/../libs/jersey-server-2.34.jar:/Users/byoon/study/kafka/Test02/kafka_client_2.8.2//bin/../libs/jetty-client-9.4.48.v20220622.jar:/Users/byoon/study/kafka/Test02/kafka_client_2.8.2//bin/../libs/jetty-continuation-9.4.48.v20220622.jar:/Users/byoon/study/kafka/Test02/kafka_client_2.8.2//bin/../libs/jetty-http-9.4.48.v20220622.jar:/Users/byoon/study/kafka/Test02/kafka_client_2.8.2//bin/../libs/jetty-io-9.4.48.v20220622.jar:/Users/byoon/study/kafka/Test02/kafka_client_2.8.2//bin/../libs/jetty-security-9.4.48.v20220622.jar:/Users/byoon/study/kafka/Test02/kafka_client_2.8.2//bin/../libs/jetty-server-9.4.48.v20220622.jar:/Users/byoon/study/kafka/Test02/kafka_client_2.8.2//bin/../libs/jetty-servlet-9.4.48.v20220622.jar:/Users/byoon/study/kafka/Test02/kafka_client_2.8.2//bin/../libs/jetty-servlets-9.4.48.v20220622.jar:/Users/byoon/study/kafka/Test02/kafka_client_2.8.2//bin/../libs/jetty-util-9.4.48.v20220622.jar:/Users/byoon/study/kafka/Test02/kafka_client_2.8.2//bin/../libs/jetty-util-ajax-9.4.48.v20220622.jar:/Users/byoon/study/kafka/Test02/kafka_client_2.8.2//bin/../libs/jline-3.12.1.jar:/Users/byoon/study/kafka/Test02/kafka_client_2.8.2//bin/../libs/jopt-simple-5.0.4.jar:/Users/byoon/study/kafka/Test02/kafka_client_2.8.2//bin/../libs/kafka-clients-2.8.2.jar:/Users/byoon/study/kafka/Test02/kafka_client_2.8.2//bin/../libs/kafka-log4j-appender-2.8.2.jar:/Users/byoon/study/kafka/Test02/kafka_client_2.8.2//bin/../libs/kafka-metadata-2.8.2.jar:/Users/byoon/study/kafka/Test02/kafka_client_2.8.2//bin/../libs/kafka-raft-2.8.2.jar:/Users/byoon/study/kafka/Test02/kafka_client_2.8.2//bin/../libs/kafka-shell-2.8.2.jar:/Users/byoon/study/kafka/Test02/kafka_client_2.8.2//bin/../libs/kafka-streams-2.8.2.jar:/Users/byoon/study/kafka/Test02/kafka_client_2.8.2//bin/../libs/kafka-streams-examples-2.8.2.jar:/Users/byoon/study/kafka/Test02/kafka_client_2.8.2//bin/../libs/kafka-streams-scala_2.13-2.8.2.jar:/Users/byoon/study/kafka/Test02/kafka_client_2.8.2//bin/../libs/kafka-streams-test-utils-2.8.2.jar:/Users/byoon/study/kafka/Test02/kafka_client_2.8.2//bin/../libs/kafka-tools-2.8.2.jar:/Users/byoon/study/kafka/Test02/kafka_client_2.8.2//bin/../libs/kafka_2.13-2.8.2-sources.jar:/Users/byoon/study/kafka/Test02/kafka_client_2.8.2//bin/../libs/kafka_2.13-2.8.2.jar:/Users/byoon/study/kafka/Test02/kafka_client_2.8.2//bin/../libs/log4j-1.2.17.jar:/Users/byoon/study/kafka/Test02/kafka_client_2.8.2//bin/../libs/lz4-java-1.7.1.jar:/Users/byoon/study/kafka/Test02/kafka_client_2.8.2//bin/../libs/maven-artifact-3.8.1.jar:/Users/byoon/study/kafka/Test02/kafka_client_2.8.2//bin/../libs/metrics-core-2.2.0.jar:/Users/byoon/study/kafka/Test02/kafka_client_2.8.2//bin/../libs/netty-buffer-4.1.73.Final.jar:/Users/byoon/study/kafka/Test02/kafka_client_2.8.2//bin/../libs/netty-codec-4.1.73.Final.jar:/Users/byoon/study/kafka/Test02/kafka_client_2.8.2//bin/../libs/netty-common-4.1.73.Final.jar:/Users/byoon/study/kafka/Test02/kafka_client_2.8.2//bin/../libs/netty-handler-4.1.73.Final.jar:/Users/byoon/study/kafka/Test02/kafka_client_2.8.2//bin/../libs/netty-resolver-4.1.73.Final.jar:/Users/byoon/study/kafka/Test02/kafka_client_2.8.2//bin/../libs/netty-tcnative-classes-2.0.46.Final.jar:/Users/byoon/study/kafka/Test02/kafka_client_2.8.2//bin/../libs/netty-transport-4.1.73.Final.jar:/Users/byoon/study/kafka/Test02/kafka_client_2.8.2//bin/../libs/netty-transport-classes-epoll-4.1.73.Final.jar:/Users/byoon/study/kafka/Test02/kafka_client_2.8.2//bin/../libs/netty-transport-native-epoll-4.1.73.Final.jar:/Users/byoon/study/kafka/Test02/kafka_client_2.8.2//bin/../libs/netty-transport-native-unix-common-4.1.73.Final.jar:/Users/byoon/study/kafka/Test02/kafka_client_2.8.2//bin/../libs/osgi-resource-locator-1.0.3.jar:/Users/byoon/study/kafka/Test02/kafka_client_2.8.2//bin/../libs/paranamer-2.8.jar:/Users/byoon/study/kafka/Test02/kafka_client_2.8.2//bin/../libs/plexus-utils-3.2.1.jar:/Users/byoon/study/kafka/Test02/kafka_client_2.8.2//bin/../libs/reflections-0.9.12.jar:/Users/byoon/study/kafka/Test02/kafka_client_2.8.2//bin/../libs/rocksdbjni-5.18.4.jar:/Users/byoon/study/kafka/Test02/kafka_client_2.8.2//bin/../libs/scala-collection-compat_2.13-2.3.0.jar:/Users/byoon/study/kafka/Test02/kafka_client_2.8.2//bin/../libs/scala-java8-compat_2.13-0.9.1.jar:/Users/byoon/study/kafka/Test02/kafka_client_2.8.2//bin/../libs/scala-library-2.13.5.jar:/Users/byoon/study/kafka/Test02/kafka_client_2.8.2//bin/../libs/scala-logging_2.13-3.9.2.jar:/Users/byoon/study/kafka/Test02/kafka_client_2.8.2//bin/../libs/scala-reflect-2.13.5.jar:/Users/byoon/study/kafka/Test02/kafka_client_2.8.2//bin/../libs/slf4j-api-1.7.30.jar:/Users/byoon/study/kafka/Test02/kafka_client_2.8.2//bin/../libs/slf4j-log4j12-1.7.30.jar:/Users/byoon/study/kafka/Test02/kafka_client_2.8.2//bin/../libs/snappy-java-1.1.8.1.jar:/Users/byoon/study/kafka/Test02/kafka_client_2.8.2//bin/../libs/zookeeper-3.5.9.jar:/Users/byoon/study/kafka/Test02/kafka_client_2.8.2//bin/../libs/zookeeper-jute-3.5.9.jar:/Users/byoon/study/kafka/Test02/kafka_client_2.8.2//bin/../libs/zstd-jni-1.4.9-1.jar
	os.spec = Mac OS X, x86_64, 10.16
	os.vcpus = 16
 (org.apache.kafka.connect.runtime.WorkerInfo:71)
[2022-12-08 11:08:44,768] INFO Scanning for plugin classes. This might take a moment ... (org.apache.kafka.connect.cli.ConnectDistributed:92)
[2022-12-08 11:08:44,787] INFO Loading plugin from: /Users/byoon/study/kafka/Test02/kafka_client_2.8.2/plugins/mongodb_connector (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:246)
[2022-12-08 11:08:45,170] INFO Registered loader: PluginClassLoader{pluginLocation=file:/Users/byoon/study/kafka/Test02/kafka_client_2.8.2/plugins/mongodb_connector/} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:269)
[2022-12-08 11:08:45,170] INFO Added plugin 'com.mongodb.kafka.connect.MongoSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-08 11:08:45,171] INFO Added plugin 'com.mongodb.kafka.connect.MongoSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-08 11:08:45,171] INFO Added plugin 'org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-08 11:08:45,171] INFO Added plugin 'org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-08 11:08:45,171] INFO Added plugin 'org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-08 11:08:45,978] INFO Registered loader: sun.misc.Launcher$AppClassLoader@764c12b6 (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:269)
[2022-12-08 11:08:45,978] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-08 11:08:45,978] INFO Added plugin 'org.apache.kafka.connect.file.FileStreamSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-08 11:08:45,978] INFO Added plugin 'org.apache.kafka.connect.tools.SchemaSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-08 11:08:45,978] INFO Added plugin 'org.apache.kafka.connect.tools.MockSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-08 11:08:45,978] INFO Added plugin 'org.apache.kafka.connect.file.FileStreamSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-08 11:08:45,979] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorCheckpointConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-08 11:08:45,979] INFO Added plugin 'org.apache.kafka.connect.tools.VerifiableSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-08 11:08:45,980] INFO Added plugin 'org.apache.kafka.connect.tools.VerifiableSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-08 11:08:45,980] INFO Added plugin 'org.apache.kafka.connect.tools.MockSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-08 11:08:45,980] INFO Added plugin 'org.apache.kafka.connect.mirror.MirrorHeartbeatConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-08 11:08:45,980] INFO Added plugin 'org.apache.kafka.connect.tools.MockConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-08 11:08:45,980] INFO Added plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-08 11:08:45,980] INFO Added plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-08 11:08:45,980] INFO Added plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-08 11:08:45,980] INFO Added plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-08 11:08:45,980] INFO Added plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-08 11:08:45,980] INFO Added plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-08 11:08:45,981] INFO Added plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-08 11:08:45,981] INFO Added plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-08 11:08:45,981] INFO Added plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-08 11:08:45,981] INFO Added plugin 'org.apache.kafka.connect.transforms.ReplaceField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-08 11:08:45,981] INFO Added plugin 'org.apache.kafka.connect.transforms.SetSchemaMetadata$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-08 11:08:45,981] INFO Added plugin 'org.apache.kafka.connect.transforms.ReplaceField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-08 11:08:45,981] INFO Added plugin 'org.apache.kafka.connect.transforms.Filter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-08 11:08:45,981] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-08 11:08:45,981] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampConverter$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-08 11:08:45,982] INFO Added plugin 'org.apache.kafka.connect.transforms.MaskField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-08 11:08:45,982] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-08 11:08:45,982] INFO Added plugin 'org.apache.kafka.connect.transforms.RegexRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-08 11:08:45,982] INFO Added plugin 'org.apache.kafka.connect.transforms.HoistField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-08 11:08:45,982] INFO Added plugin 'org.apache.kafka.connect.transforms.ValueToKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-08 11:08:45,982] INFO Added plugin 'org.apache.kafka.connect.transforms.MaskField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-08 11:08:45,982] INFO Added plugin 'org.apache.kafka.connect.transforms.Cast$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-08 11:08:45,982] INFO Added plugin 'org.apache.kafka.connect.transforms.Cast$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-08 11:08:45,982] INFO Added plugin 'org.apache.kafka.connect.runtime.PredicatedTransformation' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-08 11:08:45,982] INFO Added plugin 'org.apache.kafka.connect.transforms.ExtractField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-08 11:08:45,982] INFO Added plugin 'org.apache.kafka.connect.transforms.Flatten$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-08 11:08:45,983] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-08 11:08:45,983] INFO Added plugin 'org.apache.kafka.connect.transforms.Flatten$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-08 11:08:45,983] INFO Added plugin 'org.apache.kafka.connect.transforms.SetSchemaMetadata$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-08 11:08:45,983] INFO Added plugin 'org.apache.kafka.connect.transforms.ExtractField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-08 11:08:45,983] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampConverter$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-08 11:08:45,983] INFO Added plugin 'org.apache.kafka.connect.transforms.HoistField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-08 11:08:45,983] INFO Added plugin 'org.apache.kafka.connect.transforms.predicates.HasHeaderKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-08 11:08:45,983] INFO Added plugin 'org.apache.kafka.connect.transforms.predicates.RecordIsTombstone' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-08 11:08:45,983] INFO Added plugin 'org.apache.kafka.connect.transforms.predicates.TopicNameMatches' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-08 11:08:45,983] INFO Added plugin 'org.apache.kafka.common.config.provider.FileConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-08 11:08:45,983] INFO Added plugin 'org.apache.kafka.connect.rest.basic.auth.extension.BasicAuthSecurityRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:198)
[2022-12-08 11:08:45,984] INFO Added aliases 'MongoSinkConnector' and 'MongoSink' to plugin 'com.mongodb.kafka.connect.MongoSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-08 11:08:45,984] INFO Added aliases 'MongoSourceConnector' and 'MongoSource' to plugin 'com.mongodb.kafka.connect.MongoSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-08 11:08:45,984] INFO Added aliases 'FileStreamSinkConnector' and 'FileStreamSink' to plugin 'org.apache.kafka.connect.file.FileStreamSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-08 11:08:45,984] INFO Added aliases 'FileStreamSourceConnector' and 'FileStreamSource' to plugin 'org.apache.kafka.connect.file.FileStreamSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-08 11:08:45,985] INFO Added aliases 'MirrorCheckpointConnector' and 'MirrorCheckpoint' to plugin 'org.apache.kafka.connect.mirror.MirrorCheckpointConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-08 11:08:45,985] INFO Added aliases 'MirrorHeartbeatConnector' and 'MirrorHeartbeat' to plugin 'org.apache.kafka.connect.mirror.MirrorHeartbeatConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-08 11:08:45,985] INFO Added aliases 'MirrorSourceConnector' and 'MirrorSource' to plugin 'org.apache.kafka.connect.mirror.MirrorSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-08 11:08:45,985] INFO Added aliases 'MockConnector' and 'Mock' to plugin 'org.apache.kafka.connect.tools.MockConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-08 11:08:45,985] INFO Added aliases 'MockSinkConnector' and 'MockSink' to plugin 'org.apache.kafka.connect.tools.MockSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-08 11:08:45,985] INFO Added aliases 'MockSourceConnector' and 'MockSource' to plugin 'org.apache.kafka.connect.tools.MockSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-08 11:08:45,985] INFO Added aliases 'SchemaSourceConnector' and 'SchemaSource' to plugin 'org.apache.kafka.connect.tools.SchemaSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-08 11:08:45,986] INFO Added aliases 'VerifiableSinkConnector' and 'VerifiableSink' to plugin 'org.apache.kafka.connect.tools.VerifiableSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-08 11:08:45,986] INFO Added aliases 'VerifiableSourceConnector' and 'VerifiableSource' to plugin 'org.apache.kafka.connect.tools.VerifiableSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-08 11:08:45,986] INFO Added aliases 'ByteArrayConverter' and 'ByteArray' to plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-08 11:08:45,986] INFO Added aliases 'DoubleConverter' and 'Double' to plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-08 11:08:45,986] INFO Added aliases 'FloatConverter' and 'Float' to plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-08 11:08:45,986] INFO Added aliases 'IntegerConverter' and 'Integer' to plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-08 11:08:45,986] INFO Added aliases 'LongConverter' and 'Long' to plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-08 11:08:45,986] INFO Added aliases 'ShortConverter' and 'Short' to plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-08 11:08:45,987] INFO Added aliases 'JsonConverter' and 'Json' to plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-08 11:08:45,987] INFO Added aliases 'StringConverter' and 'String' to plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-08 11:08:45,987] INFO Added aliases 'ByteArrayConverter' and 'ByteArray' to plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-08 11:08:45,987] INFO Added aliases 'DoubleConverter' and 'Double' to plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-08 11:08:45,987] INFO Added aliases 'FloatConverter' and 'Float' to plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-08 11:08:45,987] INFO Added aliases 'IntegerConverter' and 'Integer' to plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-08 11:08:45,987] INFO Added aliases 'LongConverter' and 'Long' to plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-08 11:08:45,987] INFO Added aliases 'ShortConverter' and 'Short' to plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-08 11:08:45,988] INFO Added aliases 'JsonConverter' and 'Json' to plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-08 11:08:45,988] INFO Added alias 'SimpleHeaderConverter' to plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:424)
[2022-12-08 11:08:45,988] INFO Added aliases 'StringConverter' and 'String' to plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-08 11:08:45,988] INFO Added aliases 'PredicatedTransformation' and 'Predicated' to plugin 'org.apache.kafka.connect.runtime.PredicatedTransformation' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-08 11:08:45,989] INFO Added alias 'Filter' to plugin 'org.apache.kafka.connect.transforms.Filter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:424)
[2022-12-08 11:08:45,989] INFO Added alias 'RegexRouter' to plugin 'org.apache.kafka.connect.transforms.RegexRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:424)
[2022-12-08 11:08:45,989] INFO Added alias 'TimestampRouter' to plugin 'org.apache.kafka.connect.transforms.TimestampRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:424)
[2022-12-08 11:08:45,989] INFO Added alias 'ValueToKey' to plugin 'org.apache.kafka.connect.transforms.ValueToKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:424)
[2022-12-08 11:08:45,989] INFO Added alias 'HasHeaderKey' to plugin 'org.apache.kafka.connect.transforms.predicates.HasHeaderKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:424)
[2022-12-08 11:08:45,990] INFO Added alias 'RecordIsTombstone' to plugin 'org.apache.kafka.connect.transforms.predicates.RecordIsTombstone' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:424)
[2022-12-08 11:08:45,990] INFO Added alias 'TopicNameMatches' to plugin 'org.apache.kafka.connect.transforms.predicates.TopicNameMatches' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:424)
[2022-12-08 11:08:45,990] INFO Added alias 'BasicAuthSecurityRestExtension' to plugin 'org.apache.kafka.connect.rest.basic.auth.extension.BasicAuthSecurityRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:424)
[2022-12-08 11:08:45,990] INFO Added aliases 'AllConnectorClientConfigOverridePolicy' and 'All' to plugin 'org.apache.kafka.connect.connector.policy.AllConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-08 11:08:45,990] INFO Added aliases 'NoneConnectorClientConfigOverridePolicy' and 'None' to plugin 'org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-08 11:08:45,990] INFO Added aliases 'PrincipalConnectorClientConfigOverridePolicy' and 'Principal' to plugin 'org.apache.kafka.connect.connector.policy.PrincipalConnectorClientConfigOverridePolicy' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:427)
[2022-12-08 11:08:46,178] INFO DistributedConfig values: 
	access.control.allow.methods = 
	access.control.allow.origin = 
	admin.listeners = null
	bootstrap.servers = [localhost:29092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	config.providers = []
	config.storage.replication.factor = 2
	config.storage.topic = connect-configs
	connect.protocol = sessioned
	connections.max.idle.ms = 540000
	connector.client.config.override.policy = None
	group.id = connect-cluster
	header.converter = class org.apache.kafka.connect.storage.SimpleHeaderConverter
	heartbeat.interval.ms = 3000
	inter.worker.key.generation.algorithm = HmacSHA256
	inter.worker.key.size = null
	inter.worker.key.ttl.ms = 3600000
	inter.worker.signature.algorithm = HmacSHA256
	inter.worker.verification.algorithms = [HmacSHA256]
	internal.key.converter = class org.apache.kafka.connect.json.JsonConverter
	internal.value.converter = class org.apache.kafka.connect.json.JsonConverter
	key.converter = class org.apache.kafka.connect.json.JsonConverter
	listeners = null
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	offset.flush.interval.ms = 60000
	offset.flush.timeout.ms = 5000
	offset.storage.partitions = 25
	offset.storage.replication.factor = 2
	offset.storage.topic = connect-offsets
	plugin.path = [/Users/byoon/study/kafka/Test02/kafka_client_2.8.2/plugins]
	rebalance.timeout.ms = 60000
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 40000
	response.http.headers.config = 
	rest.advertised.host.name = null
	rest.advertised.listener = null
	rest.advertised.port = null
	rest.extension.classes = []
	rest.host.name = localhost
	rest.port = 8083
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	scheduled.rebalance.max.delay.ms = 300000
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	status.storage.partitions = 5
	status.storage.replication.factor = 2
	status.storage.topic = connect-status
	task.shutdown.graceful.timeout.ms = 5000
	topic.creation.enable = true
	topic.tracking.allow.reset = true
	topic.tracking.enable = true
	value.converter = class org.apache.kafka.connect.json.JsonConverter
	worker.sync.timeout.ms = 3000
	worker.unsync.backoff.ms = 300000
 (org.apache.kafka.connect.runtime.distributed.DistributedConfig:372)
[2022-12-08 11:08:46,181] INFO Creating Kafka admin client (org.apache.kafka.connect.util.ConnectUtils:49)
[2022-12-08 11:08:46,183] INFO AdminClientConfig values: 
	bootstrap.servers = [localhost:29092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
 (org.apache.kafka.clients.admin.AdminClientConfig:372)
[2022-12-08 11:08:46,262] WARN The configuration 'config.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-08 11:08:46,262] WARN The configuration 'group.id' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-08 11:08:46,263] WARN The configuration 'status.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-08 11:08:46,263] WARN The configuration 'rest.host.name' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-08 11:08:46,263] WARN The configuration 'plugin.path' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-08 11:08:46,263] WARN The configuration 'topic.creation.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-08 11:08:46,263] WARN The configuration 'config.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-08 11:08:46,263] WARN The configuration 'rest.port' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-08 11:08:46,263] WARN The configuration 'key.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-08 11:08:46,264] WARN The configuration 'status.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-08 11:08:46,264] WARN The configuration 'value.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-08 11:08:46,264] WARN The configuration 'offset.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-08 11:08:46,264] WARN The configuration 'offset.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-08 11:08:46,271] WARN The configuration 'value.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-08 11:08:46,271] WARN The configuration 'key.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-08 11:08:46,272] INFO Kafka version: 2.8.2 (org.apache.kafka.common.utils.AppInfoParser:119)
[2022-12-08 11:08:46,272] INFO Kafka commitId: 3146c6ff4a24cc24 (org.apache.kafka.common.utils.AppInfoParser:120)
[2022-12-08 11:08:46,272] INFO Kafka startTimeMs: 1670465326271 (org.apache.kafka.common.utils.AppInfoParser:121)
[2022-12-08 11:08:46,570] INFO Kafka cluster ID: AJw0mIIBTzmvGtlyebvsaQ (org.apache.kafka.connect.util.ConnectUtils:65)
[2022-12-08 11:08:46,571] INFO App info kafka.admin.client for adminclient-1 unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2022-12-08 11:08:46,578] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:659)
[2022-12-08 11:08:46,578] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:663)
[2022-12-08 11:08:46,578] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:669)
[2022-12-08 11:08:46,588] INFO Logging initialized @2412ms to org.eclipse.jetty.util.log.Slf4jLog (org.eclipse.jetty.util.log:170)
[2022-12-08 11:08:46,631] INFO Added connector for http://localhost:8083 (org.apache.kafka.connect.runtime.rest.RestServer:132)
[2022-12-08 11:08:46,632] INFO Initializing REST server (org.apache.kafka.connect.runtime.rest.RestServer:204)
[2022-12-08 11:08:46,638] INFO jetty-9.4.48.v20220622; built: 2022-06-21T20:42:25.880Z; git: 6b67c5719d1f4371b33655ff2d047d24e171e49a; jvm 1.8.0_152-b16 (org.eclipse.jetty.server.Server:375)
[2022-12-08 11:08:46,662] INFO Started http_localhost8083@1c25b8a7{HTTP/1.1, (http/1.1)}{localhost:8083} (org.eclipse.jetty.server.AbstractConnector:333)
[2022-12-08 11:08:46,662] INFO Started @2486ms (org.eclipse.jetty.server.Server:415)
[2022-12-08 11:08:46,680] INFO Advertised URI: http://localhost:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:371)
[2022-12-08 11:08:46,680] INFO REST server listening at http://localhost:8083/, advertising URL http://localhost:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:219)
[2022-12-08 11:08:46,680] INFO Advertised URI: http://localhost:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:371)
[2022-12-08 11:08:46,681] INFO REST admin endpoints at http://localhost:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:220)
[2022-12-08 11:08:46,681] INFO Advertised URI: http://localhost:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:371)
[2022-12-08 11:08:46,683] INFO Creating Kafka admin client (org.apache.kafka.connect.util.ConnectUtils:49)
[2022-12-08 11:08:46,683] INFO AdminClientConfig values: 
	bootstrap.servers = [localhost:29092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
 (org.apache.kafka.clients.admin.AdminClientConfig:372)
[2022-12-08 11:08:46,687] WARN The configuration 'config.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-08 11:08:46,687] WARN The configuration 'group.id' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-08 11:08:46,687] WARN The configuration 'status.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-08 11:08:46,687] WARN The configuration 'rest.host.name' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-08 11:08:46,687] WARN The configuration 'plugin.path' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-08 11:08:46,688] WARN The configuration 'topic.creation.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-08 11:08:46,688] WARN The configuration 'config.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-08 11:08:46,688] WARN The configuration 'rest.port' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-08 11:08:46,688] WARN The configuration 'key.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-08 11:08:46,688] WARN The configuration 'status.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-08 11:08:46,688] WARN The configuration 'value.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-08 11:08:46,688] WARN The configuration 'offset.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-08 11:08:46,688] WARN The configuration 'offset.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-08 11:08:46,688] WARN The configuration 'value.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-08 11:08:46,689] WARN The configuration 'key.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-08 11:08:46,689] INFO Kafka version: 2.8.2 (org.apache.kafka.common.utils.AppInfoParser:119)
[2022-12-08 11:08:46,689] INFO Kafka commitId: 3146c6ff4a24cc24 (org.apache.kafka.common.utils.AppInfoParser:120)
[2022-12-08 11:08:46,689] INFO Kafka startTimeMs: 1670465326689 (org.apache.kafka.common.utils.AppInfoParser:121)
[2022-12-08 11:08:46,700] INFO Kafka cluster ID: AJw0mIIBTzmvGtlyebvsaQ (org.apache.kafka.connect.util.ConnectUtils:65)
[2022-12-08 11:08:46,700] INFO App info kafka.admin.client for adminclient-2 unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2022-12-08 11:08:46,702] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:659)
[2022-12-08 11:08:46,702] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:663)
[2022-12-08 11:08:46,702] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:669)
[2022-12-08 11:08:46,707] INFO Setting up None Policy for ConnectorClientConfigOverride. This will disallow any client configuration to be overridden (org.apache.kafka.connect.connector.policy.NoneConnectorClientConfigOverridePolicy:45)
[2022-12-08 11:08:46,713] INFO Creating Kafka admin client (org.apache.kafka.connect.util.ConnectUtils:49)
[2022-12-08 11:08:46,713] INFO AdminClientConfig values: 
	bootstrap.servers = [localhost:29092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
 (org.apache.kafka.clients.admin.AdminClientConfig:372)
[2022-12-08 11:08:46,717] WARN The configuration 'config.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-08 11:08:46,717] WARN The configuration 'group.id' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-08 11:08:46,717] WARN The configuration 'status.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-08 11:08:46,717] WARN The configuration 'rest.host.name' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-08 11:08:46,717] WARN The configuration 'plugin.path' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-08 11:08:46,717] WARN The configuration 'topic.creation.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-08 11:08:46,717] WARN The configuration 'config.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-08 11:08:46,718] WARN The configuration 'rest.port' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-08 11:08:46,718] WARN The configuration 'key.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-08 11:08:46,718] WARN The configuration 'status.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-08 11:08:46,718] WARN The configuration 'value.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-08 11:08:46,726] WARN The configuration 'offset.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-08 11:08:46,726] WARN The configuration 'offset.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-08 11:08:46,726] WARN The configuration 'value.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-08 11:08:46,726] WARN The configuration 'key.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-08 11:08:46,726] INFO Kafka version: 2.8.2 (org.apache.kafka.common.utils.AppInfoParser:119)
[2022-12-08 11:08:46,726] INFO Kafka commitId: 3146c6ff4a24cc24 (org.apache.kafka.common.utils.AppInfoParser:120)
[2022-12-08 11:08:46,727] INFO Kafka startTimeMs: 1670465326726 (org.apache.kafka.common.utils.AppInfoParser:121)
[2022-12-08 11:08:46,737] INFO Kafka cluster ID: AJw0mIIBTzmvGtlyebvsaQ (org.apache.kafka.connect.util.ConnectUtils:65)
[2022-12-08 11:08:46,738] INFO App info kafka.admin.client for adminclient-3 unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2022-12-08 11:08:46,739] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:659)
[2022-12-08 11:08:46,739] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:663)
[2022-12-08 11:08:46,739] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:669)
[2022-12-08 11:08:46,742] INFO Kafka version: 2.8.2 (org.apache.kafka.common.utils.AppInfoParser:119)
[2022-12-08 11:08:46,742] INFO Kafka commitId: 3146c6ff4a24cc24 (org.apache.kafka.common.utils.AppInfoParser:120)
[2022-12-08 11:08:46,742] INFO Kafka startTimeMs: 1670465326742 (org.apache.kafka.common.utils.AppInfoParser:121)
[2022-12-08 11:08:46,846] INFO JsonConverterConfig values: 
	converter.type = key
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:372)
[2022-12-08 11:08:46,847] INFO JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:372)
[2022-12-08 11:08:46,848] INFO Creating Kafka admin client (org.apache.kafka.connect.util.ConnectUtils:49)
[2022-12-08 11:08:46,848] INFO AdminClientConfig values: 
	bootstrap.servers = [localhost:29092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
 (org.apache.kafka.clients.admin.AdminClientConfig:372)
[2022-12-08 11:08:46,851] WARN The configuration 'config.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-08 11:08:46,851] WARN The configuration 'group.id' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-08 11:08:46,851] WARN The configuration 'status.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-08 11:08:46,851] WARN The configuration 'rest.host.name' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-08 11:08:46,851] WARN The configuration 'plugin.path' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-08 11:08:46,851] WARN The configuration 'topic.creation.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-08 11:08:46,851] WARN The configuration 'config.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-08 11:08:46,851] WARN The configuration 'rest.port' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-08 11:08:46,852] WARN The configuration 'key.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-08 11:08:46,852] WARN The configuration 'status.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-08 11:08:46,852] WARN The configuration 'value.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-08 11:08:46,859] WARN The configuration 'offset.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-08 11:08:46,859] WARN The configuration 'offset.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-08 11:08:46,859] WARN The configuration 'value.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-08 11:08:46,859] WARN The configuration 'key.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-08 11:08:46,859] INFO Kafka version: 2.8.2 (org.apache.kafka.common.utils.AppInfoParser:119)
[2022-12-08 11:08:46,860] INFO Kafka commitId: 3146c6ff4a24cc24 (org.apache.kafka.common.utils.AppInfoParser:120)
[2022-12-08 11:08:46,860] INFO Kafka startTimeMs: 1670465326859 (org.apache.kafka.common.utils.AppInfoParser:121)
[2022-12-08 11:08:46,869] INFO Kafka cluster ID: AJw0mIIBTzmvGtlyebvsaQ (org.apache.kafka.connect.util.ConnectUtils:65)
[2022-12-08 11:08:46,870] INFO App info kafka.admin.client for adminclient-4 unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2022-12-08 11:08:46,871] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:659)
[2022-12-08 11:08:46,871] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:663)
[2022-12-08 11:08:46,871] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:669)
[2022-12-08 11:08:46,876] INFO Creating Kafka admin client (org.apache.kafka.connect.util.ConnectUtils:49)
[2022-12-08 11:08:46,876] INFO AdminClientConfig values: 
	bootstrap.servers = [localhost:29092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
 (org.apache.kafka.clients.admin.AdminClientConfig:372)
[2022-12-08 11:08:46,878] WARN The configuration 'config.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-08 11:08:46,878] WARN The configuration 'group.id' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-08 11:08:46,878] WARN The configuration 'status.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-08 11:08:46,878] WARN The configuration 'rest.host.name' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-08 11:08:46,878] WARN The configuration 'plugin.path' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-08 11:08:46,878] WARN The configuration 'topic.creation.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-08 11:08:46,878] WARN The configuration 'config.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-08 11:08:46,878] WARN The configuration 'rest.port' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-08 11:08:46,879] WARN The configuration 'key.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-08 11:08:46,879] WARN The configuration 'status.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-08 11:08:46,879] WARN The configuration 'value.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-08 11:08:46,879] WARN The configuration 'offset.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-08 11:08:46,879] WARN The configuration 'offset.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-08 11:08:46,879] WARN The configuration 'value.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-08 11:08:46,879] WARN The configuration 'key.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-08 11:08:46,879] INFO Kafka version: 2.8.2 (org.apache.kafka.common.utils.AppInfoParser:119)
[2022-12-08 11:08:46,879] INFO Kafka commitId: 3146c6ff4a24cc24 (org.apache.kafka.common.utils.AppInfoParser:120)
[2022-12-08 11:08:46,879] INFO Kafka startTimeMs: 1670465326879 (org.apache.kafka.common.utils.AppInfoParser:121)
[2022-12-08 11:08:46,887] INFO Kafka cluster ID: AJw0mIIBTzmvGtlyebvsaQ (org.apache.kafka.connect.util.ConnectUtils:65)
[2022-12-08 11:08:46,887] INFO App info kafka.admin.client for adminclient-5 unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2022-12-08 11:08:46,889] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:659)
[2022-12-08 11:08:46,889] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:663)
[2022-12-08 11:08:46,889] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:669)
[2022-12-08 11:08:46,892] INFO Creating Kafka admin client (org.apache.kafka.connect.util.ConnectUtils:49)
[2022-12-08 11:08:46,892] INFO AdminClientConfig values: 
	bootstrap.servers = [localhost:29092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
 (org.apache.kafka.clients.admin.AdminClientConfig:372)
[2022-12-08 11:08:46,894] WARN The configuration 'config.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-08 11:08:46,894] WARN The configuration 'group.id' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-08 11:08:46,894] WARN The configuration 'status.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-08 11:08:46,894] WARN The configuration 'rest.host.name' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-08 11:08:46,894] WARN The configuration 'plugin.path' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-08 11:08:46,894] WARN The configuration 'topic.creation.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-08 11:08:46,894] WARN The configuration 'config.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-08 11:08:46,894] WARN The configuration 'rest.port' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-08 11:08:46,894] WARN The configuration 'key.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-08 11:08:46,894] WARN The configuration 'status.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-08 11:08:46,894] WARN The configuration 'value.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-08 11:08:46,895] WARN The configuration 'offset.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-08 11:08:46,895] WARN The configuration 'offset.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-08 11:08:46,895] WARN The configuration 'value.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-08 11:08:46,895] WARN The configuration 'key.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-08 11:08:46,895] INFO Kafka version: 2.8.2 (org.apache.kafka.common.utils.AppInfoParser:119)
[2022-12-08 11:08:46,895] INFO Kafka commitId: 3146c6ff4a24cc24 (org.apache.kafka.common.utils.AppInfoParser:120)
[2022-12-08 11:08:46,895] INFO Kafka startTimeMs: 1670465326895 (org.apache.kafka.common.utils.AppInfoParser:121)
[2022-12-08 11:08:46,903] INFO Kafka cluster ID: AJw0mIIBTzmvGtlyebvsaQ (org.apache.kafka.connect.util.ConnectUtils:65)
[2022-12-08 11:08:46,904] INFO App info kafka.admin.client for adminclient-6 unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2022-12-08 11:08:46,905] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:659)
[2022-12-08 11:08:46,905] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:663)
[2022-12-08 11:08:46,905] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:669)
[2022-12-08 11:08:46,919] INFO Creating Kafka admin client (org.apache.kafka.connect.util.ConnectUtils:49)
[2022-12-08 11:08:46,919] INFO AdminClientConfig values: 
	bootstrap.servers = [localhost:29092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
 (org.apache.kafka.clients.admin.AdminClientConfig:372)
[2022-12-08 11:08:46,921] WARN The configuration 'config.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-08 11:08:46,921] WARN The configuration 'group.id' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-08 11:08:46,921] WARN The configuration 'status.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-08 11:08:46,921] WARN The configuration 'rest.host.name' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-08 11:08:46,921] WARN The configuration 'plugin.path' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-08 11:08:46,921] WARN The configuration 'topic.creation.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-08 11:08:46,921] WARN The configuration 'config.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-08 11:08:46,921] WARN The configuration 'rest.port' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-08 11:08:46,921] WARN The configuration 'key.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-08 11:08:46,929] WARN The configuration 'status.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-08 11:08:46,929] WARN The configuration 'value.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-08 11:08:46,929] WARN The configuration 'offset.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-08 11:08:46,929] WARN The configuration 'offset.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-08 11:08:46,929] WARN The configuration 'value.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-08 11:08:46,929] WARN The configuration 'key.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-08 11:08:46,929] INFO Kafka version: 2.8.2 (org.apache.kafka.common.utils.AppInfoParser:119)
[2022-12-08 11:08:46,930] INFO Kafka commitId: 3146c6ff4a24cc24 (org.apache.kafka.common.utils.AppInfoParser:120)
[2022-12-08 11:08:46,930] INFO Kafka startTimeMs: 1670465326929 (org.apache.kafka.common.utils.AppInfoParser:121)
[2022-12-08 11:08:46,938] INFO Kafka cluster ID: AJw0mIIBTzmvGtlyebvsaQ (org.apache.kafka.connect.util.ConnectUtils:65)
[2022-12-08 11:08:46,938] INFO App info kafka.admin.client for adminclient-7 unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2022-12-08 11:08:46,939] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:659)
[2022-12-08 11:08:46,939] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:663)
[2022-12-08 11:08:46,939] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:669)
[2022-12-08 11:08:46,956] INFO Kafka version: 2.8.2 (org.apache.kafka.common.utils.AppInfoParser:119)
[2022-12-08 11:08:46,956] INFO Kafka commitId: 3146c6ff4a24cc24 (org.apache.kafka.common.utils.AppInfoParser:120)
[2022-12-08 11:08:46,956] INFO Kafka startTimeMs: 1670465326956 (org.apache.kafka.common.utils.AppInfoParser:121)
[2022-12-08 11:08:46,958] INFO Kafka Connect distributed worker initialization took 2190ms (org.apache.kafka.connect.cli.ConnectDistributed:138)
[2022-12-08 11:08:46,958] INFO Kafka Connect starting (org.apache.kafka.connect.runtime.Connect:51)
[2022-12-08 11:08:46,959] INFO Initializing REST resources (org.apache.kafka.connect.runtime.rest.RestServer:224)
[2022-12-08 11:08:46,959] INFO [Worker clientId=connect-1, groupId=connect-cluster] Herder starting (org.apache.kafka.connect.runtime.distributed.DistributedHerder:308)
[2022-12-08 11:08:46,959] INFO Worker starting (org.apache.kafka.connect.runtime.Worker:191)
[2022-12-08 11:08:46,959] INFO Starting KafkaOffsetBackingStore (org.apache.kafka.connect.storage.KafkaOffsetBackingStore:144)
[2022-12-08 11:08:46,959] INFO Starting KafkaBasedLog with topic connect-offsets (org.apache.kafka.connect.util.KafkaBasedLog:166)
[2022-12-08 11:08:46,960] INFO AdminClientConfig values: 
	bootstrap.servers = [localhost:29092]
	client.dns.lookup = use_all_dns_ips
	client.id = 
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
 (org.apache.kafka.clients.admin.AdminClientConfig:372)
[2022-12-08 11:08:46,961] WARN The configuration 'config.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-08 11:08:46,962] WARN The configuration 'metrics.context.connect.group.id' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-08 11:08:46,962] WARN The configuration 'group.id' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-08 11:08:46,962] WARN The configuration 'status.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-08 11:08:46,962] WARN The configuration 'rest.host.name' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-08 11:08:46,962] WARN The configuration 'plugin.path' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-08 11:08:46,962] WARN The configuration 'topic.creation.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-08 11:08:46,962] WARN The configuration 'config.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-08 11:08:46,962] WARN The configuration 'rest.port' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-08 11:08:46,962] WARN The configuration 'key.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-08 11:08:46,962] WARN The configuration 'metrics.context.connect.kafka.cluster.id' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-08 11:08:46,962] WARN The configuration 'status.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-08 11:08:46,962] WARN The configuration 'value.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-08 11:08:46,962] WARN The configuration 'offset.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-08 11:08:46,962] WARN The configuration 'offset.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-08 11:08:46,963] WARN The configuration 'value.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-08 11:08:46,963] WARN The configuration 'key.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:380)
[2022-12-08 11:08:46,963] INFO Kafka version: 2.8.2 (org.apache.kafka.common.utils.AppInfoParser:119)
[2022-12-08 11:08:46,963] INFO Kafka commitId: 3146c6ff4a24cc24 (org.apache.kafka.common.utils.AppInfoParser:120)
[2022-12-08 11:08:46,963] INFO Kafka startTimeMs: 1670465326963 (org.apache.kafka.common.utils.AppInfoParser:121)
[2022-12-08 11:08:46,994] INFO Adding admin resources to main listener (org.apache.kafka.connect.runtime.rest.RestServer:241)
[2022-12-08 11:08:47,001] INFO ProducerConfig values: 
	acks = -1
	batch.size = 16384
	bootstrap.servers = [localhost:29092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-1
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 2147483647
	enable.idempotence = false
	interceptor.classes = []
	internal.auto.downgrade.txn.commit = false
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
 (org.apache.kafka.clients.producer.ProducerConfig:372)
[2022-12-08 11:08:47,015] WARN The configuration 'config.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:380)
[2022-12-08 11:08:47,016] WARN The configuration 'metrics.context.connect.group.id' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:380)
[2022-12-08 11:08:47,016] WARN The configuration 'group.id' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:380)
[2022-12-08 11:08:47,016] WARN The configuration 'status.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:380)
[2022-12-08 11:08:47,016] WARN The configuration 'rest.host.name' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:380)
[2022-12-08 11:08:47,016] WARN The configuration 'plugin.path' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:380)
[2022-12-08 11:08:47,016] WARN The configuration 'topic.creation.enable' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:380)
[2022-12-08 11:08:47,016] WARN The configuration 'config.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:380)
[2022-12-08 11:08:47,016] WARN The configuration 'rest.port' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:380)
[2022-12-08 11:08:47,016] WARN The configuration 'key.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:380)
[2022-12-08 11:08:47,016] WARN The configuration 'metrics.context.connect.kafka.cluster.id' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:380)
[2022-12-08 11:08:47,016] WARN The configuration 'status.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:380)
[2022-12-08 11:08:47,016] WARN The configuration 'value.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:380)
[2022-12-08 11:08:47,016] WARN The configuration 'offset.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:380)
[2022-12-08 11:08:47,016] WARN The configuration 'offset.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:380)
[2022-12-08 11:08:47,016] WARN The configuration 'value.converter' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:380)
[2022-12-08 11:08:47,017] WARN The configuration 'key.converter' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:380)
[2022-12-08 11:08:47,017] INFO Kafka version: 2.8.2 (org.apache.kafka.common.utils.AppInfoParser:119)
[2022-12-08 11:08:47,017] INFO Kafka commitId: 3146c6ff4a24cc24 (org.apache.kafka.common.utils.AppInfoParser:120)
[2022-12-08 11:08:47,017] INFO Kafka startTimeMs: 1670465327017 (org.apache.kafka.common.utils.AppInfoParser:121)
[2022-12-08 11:08:47,023] INFO ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:29092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-connect-cluster-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-cluster
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:372)
[2022-12-08 11:08:47,025] INFO [Producer clientId=producer-1] Cluster ID: AJw0mIIBTzmvGtlyebvsaQ (org.apache.kafka.clients.Metadata:287)
[2022-12-08 11:08:47,065] WARN The configuration 'config.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:380)
[2022-12-08 11:08:47,066] WARN The configuration 'metrics.context.connect.group.id' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:380)
[2022-12-08 11:08:47,066] WARN The configuration 'status.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:380)
[2022-12-08 11:08:47,066] WARN The configuration 'rest.host.name' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:380)
[2022-12-08 11:08:47,066] WARN The configuration 'plugin.path' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:380)
[2022-12-08 11:08:47,066] WARN The configuration 'topic.creation.enable' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:380)
[2022-12-08 11:08:47,066] WARN The configuration 'config.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:380)
[2022-12-08 11:08:47,066] WARN The configuration 'rest.port' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:380)
[2022-12-08 11:08:47,066] WARN The configuration 'key.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:380)
[2022-12-08 11:08:47,071] WARN The configuration 'metrics.context.connect.kafka.cluster.id' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:380)
[2022-12-08 11:08:47,071] WARN The configuration 'status.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:380)
[2022-12-08 11:08:47,071] WARN The configuration 'value.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:380)
[2022-12-08 11:08:47,071] WARN The configuration 'offset.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:380)
[2022-12-08 11:08:47,072] WARN The configuration 'offset.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:380)
[2022-12-08 11:08:47,072] WARN The configuration 'value.converter' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:380)
[2022-12-08 11:08:47,072] WARN The configuration 'key.converter' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:380)
[2022-12-08 11:08:47,072] INFO Kafka version: 2.8.2 (org.apache.kafka.common.utils.AppInfoParser:119)
[2022-12-08 11:08:47,072] INFO Kafka commitId: 3146c6ff4a24cc24 (org.apache.kafka.common.utils.AppInfoParser:120)
[2022-12-08 11:08:47,072] INFO Kafka startTimeMs: 1670465327072 (org.apache.kafka.common.utils.AppInfoParser:121)
[2022-12-08 11:08:47,081] INFO [Consumer clientId=consumer-connect-cluster-1, groupId=connect-cluster] Cluster ID: AJw0mIIBTzmvGtlyebvsaQ (org.apache.kafka.clients.Metadata:287)
[2022-12-08 11:08:47,085] INFO DefaultSessionIdManager workerName=node0 (org.eclipse.jetty.server.session:334)
[2022-12-08 11:08:47,085] INFO No SessionScavenger set, using defaults (org.eclipse.jetty.server.session:339)
[2022-12-08 11:08:47,086] INFO node0 Scavenging every 660000ms (org.eclipse.jetty.server.session:132)
[2022-12-08 11:08:47,088] INFO [Consumer clientId=consumer-connect-cluster-1, groupId=connect-cluster] Subscribed to partition(s): connect-offsets-0, connect-offsets-5, connect-offsets-10, connect-offsets-20, connect-offsets-15, connect-offsets-9, connect-offsets-11, connect-offsets-4, connect-offsets-16, connect-offsets-17, connect-offsets-3, connect-offsets-24, connect-offsets-23, connect-offsets-13, connect-offsets-18, connect-offsets-22, connect-offsets-8, connect-offsets-2, connect-offsets-12, connect-offsets-19, connect-offsets-14, connect-offsets-1, connect-offsets-6, connect-offsets-7, connect-offsets-21 (org.apache.kafka.clients.consumer.KafkaConsumer:1120)
[2022-12-08 11:08:47,102] INFO [Consumer clientId=consumer-connect-cluster-1, groupId=connect-cluster] Seeking to EARLIEST offset of partition connect-offsets-0 (org.apache.kafka.clients.consumer.internals.SubscriptionState:619)
[2022-12-08 11:08:47,103] INFO [Consumer clientId=consumer-connect-cluster-1, groupId=connect-cluster] Seeking to EARLIEST offset of partition connect-offsets-5 (org.apache.kafka.clients.consumer.internals.SubscriptionState:619)
[2022-12-08 11:08:47,103] INFO [Consumer clientId=consumer-connect-cluster-1, groupId=connect-cluster] Seeking to EARLIEST offset of partition connect-offsets-10 (org.apache.kafka.clients.consumer.internals.SubscriptionState:619)
[2022-12-08 11:08:47,103] INFO [Consumer clientId=consumer-connect-cluster-1, groupId=connect-cluster] Seeking to EARLIEST offset of partition connect-offsets-20 (org.apache.kafka.clients.consumer.internals.SubscriptionState:619)
[2022-12-08 11:08:47,103] INFO [Consumer clientId=consumer-connect-cluster-1, groupId=connect-cluster] Seeking to EARLIEST offset of partition connect-offsets-15 (org.apache.kafka.clients.consumer.internals.SubscriptionState:619)
[2022-12-08 11:08:47,103] INFO [Consumer clientId=consumer-connect-cluster-1, groupId=connect-cluster] Seeking to EARLIEST offset of partition connect-offsets-9 (org.apache.kafka.clients.consumer.internals.SubscriptionState:619)
[2022-12-08 11:08:47,103] INFO [Consumer clientId=consumer-connect-cluster-1, groupId=connect-cluster] Seeking to EARLIEST offset of partition connect-offsets-11 (org.apache.kafka.clients.consumer.internals.SubscriptionState:619)
[2022-12-08 11:08:47,103] INFO [Consumer clientId=consumer-connect-cluster-1, groupId=connect-cluster] Seeking to EARLIEST offset of partition connect-offsets-4 (org.apache.kafka.clients.consumer.internals.SubscriptionState:619)
[2022-12-08 11:08:47,103] INFO [Consumer clientId=consumer-connect-cluster-1, groupId=connect-cluster] Seeking to EARLIEST offset of partition connect-offsets-16 (org.apache.kafka.clients.consumer.internals.SubscriptionState:619)
[2022-12-08 11:08:47,103] INFO [Consumer clientId=consumer-connect-cluster-1, groupId=connect-cluster] Seeking to EARLIEST offset of partition connect-offsets-17 (org.apache.kafka.clients.consumer.internals.SubscriptionState:619)
[2022-12-08 11:08:47,103] INFO [Consumer clientId=consumer-connect-cluster-1, groupId=connect-cluster] Seeking to EARLIEST offset of partition connect-offsets-3 (org.apache.kafka.clients.consumer.internals.SubscriptionState:619)
[2022-12-08 11:08:47,103] INFO [Consumer clientId=consumer-connect-cluster-1, groupId=connect-cluster] Seeking to EARLIEST offset of partition connect-offsets-24 (org.apache.kafka.clients.consumer.internals.SubscriptionState:619)
[2022-12-08 11:08:47,104] INFO [Consumer clientId=consumer-connect-cluster-1, groupId=connect-cluster] Seeking to EARLIEST offset of partition connect-offsets-23 (org.apache.kafka.clients.consumer.internals.SubscriptionState:619)
[2022-12-08 11:08:47,104] INFO [Consumer clientId=consumer-connect-cluster-1, groupId=connect-cluster] Seeking to EARLIEST offset of partition connect-offsets-13 (org.apache.kafka.clients.consumer.internals.SubscriptionState:619)
[2022-12-08 11:08:47,104] INFO [Consumer clientId=consumer-connect-cluster-1, groupId=connect-cluster] Seeking to EARLIEST offset of partition connect-offsets-18 (org.apache.kafka.clients.consumer.internals.SubscriptionState:619)
[2022-12-08 11:08:47,104] INFO [Consumer clientId=consumer-connect-cluster-1, groupId=connect-cluster] Seeking to EARLIEST offset of partition connect-offsets-22 (org.apache.kafka.clients.consumer.internals.SubscriptionState:619)
[2022-12-08 11:08:47,104] INFO [Consumer clientId=consumer-connect-cluster-1, groupId=connect-cluster] Seeking to EARLIEST offset of partition connect-offsets-8 (org.apache.kafka.clients.consumer.internals.SubscriptionState:619)
[2022-12-08 11:08:47,104] INFO [Consumer clientId=consumer-connect-cluster-1, groupId=connect-cluster] Seeking to EARLIEST offset of partition connect-offsets-2 (org.apache.kafka.clients.consumer.internals.SubscriptionState:619)
[2022-12-08 11:08:47,104] INFO [Consumer clientId=consumer-connect-cluster-1, groupId=connect-cluster] Seeking to EARLIEST offset of partition connect-offsets-12 (org.apache.kafka.clients.consumer.internals.SubscriptionState:619)
[2022-12-08 11:08:47,104] INFO [Consumer clientId=consumer-connect-cluster-1, groupId=connect-cluster] Seeking to EARLIEST offset of partition connect-offsets-19 (org.apache.kafka.clients.consumer.internals.SubscriptionState:619)
[2022-12-08 11:08:47,104] INFO [Consumer clientId=consumer-connect-cluster-1, groupId=connect-cluster] Seeking to EARLIEST offset of partition connect-offsets-14 (org.apache.kafka.clients.consumer.internals.SubscriptionState:619)
[2022-12-08 11:08:47,104] INFO [Consumer clientId=consumer-connect-cluster-1, groupId=connect-cluster] Seeking to EARLIEST offset of partition connect-offsets-1 (org.apache.kafka.clients.consumer.internals.SubscriptionState:619)
[2022-12-08 11:08:47,104] INFO [Consumer clientId=consumer-connect-cluster-1, groupId=connect-cluster] Seeking to EARLIEST offset of partition connect-offsets-6 (org.apache.kafka.clients.consumer.internals.SubscriptionState:619)
[2022-12-08 11:08:47,104] INFO [Consumer clientId=consumer-connect-cluster-1, groupId=connect-cluster] Seeking to EARLIEST offset of partition connect-offsets-7 (org.apache.kafka.clients.consumer.internals.SubscriptionState:619)
[2022-12-08 11:08:47,104] INFO [Consumer clientId=consumer-connect-cluster-1, groupId=connect-cluster] Seeking to EARLIEST offset of partition connect-offsets-21 (org.apache.kafka.clients.consumer.internals.SubscriptionState:619)
[2022-12-08 11:08:47,133] INFO [Consumer clientId=consumer-connect-cluster-1, groupId=connect-cluster] Resetting the last seen epoch of partition connect-offsets-0 to 4 since the associated topicId changed from null to AybVz0y6SneG4Es9YlbnWQ (org.apache.kafka.clients.Metadata:401)
[2022-12-08 11:08:47,134] INFO [Consumer clientId=consumer-connect-cluster-1, groupId=connect-cluster] Resetting the last seen epoch of partition connect-offsets-5 to 4 since the associated topicId changed from null to AybVz0y6SneG4Es9YlbnWQ (org.apache.kafka.clients.Metadata:401)
[2022-12-08 11:08:47,134] INFO [Consumer clientId=consumer-connect-cluster-1, groupId=connect-cluster] Resetting the last seen epoch of partition connect-offsets-10 to 3 since the associated topicId changed from null to AybVz0y6SneG4Es9YlbnWQ (org.apache.kafka.clients.Metadata:401)
[2022-12-08 11:08:47,134] INFO [Consumer clientId=consumer-connect-cluster-1, groupId=connect-cluster] Resetting the last seen epoch of partition connect-offsets-20 to 4 since the associated topicId changed from null to AybVz0y6SneG4Es9YlbnWQ (org.apache.kafka.clients.Metadata:401)
[2022-12-08 11:08:47,134] INFO [Consumer clientId=consumer-connect-cluster-1, groupId=connect-cluster] Resetting the last seen epoch of partition connect-offsets-15 to 5 since the associated topicId changed from null to AybVz0y6SneG4Es9YlbnWQ (org.apache.kafka.clients.Metadata:401)
[2022-12-08 11:08:47,135] INFO [Consumer clientId=consumer-connect-cluster-1, groupId=connect-cluster] Resetting the last seen epoch of partition connect-offsets-9 to 5 since the associated topicId changed from null to AybVz0y6SneG4Es9YlbnWQ (org.apache.kafka.clients.Metadata:401)
[2022-12-08 11:08:47,135] INFO [Consumer clientId=consumer-connect-cluster-1, groupId=connect-cluster] Resetting the last seen epoch of partition connect-offsets-11 to 4 since the associated topicId changed from null to AybVz0y6SneG4Es9YlbnWQ (org.apache.kafka.clients.Metadata:401)
[2022-12-08 11:08:47,135] INFO [Consumer clientId=consumer-connect-cluster-1, groupId=connect-cluster] Resetting the last seen epoch of partition connect-offsets-4 to 3 since the associated topicId changed from null to AybVz0y6SneG4Es9YlbnWQ (org.apache.kafka.clients.Metadata:401)
[2022-12-08 11:08:47,135] INFO [Consumer clientId=consumer-connect-cluster-1, groupId=connect-cluster] Resetting the last seen epoch of partition connect-offsets-16 to 3 since the associated topicId changed from null to AybVz0y6SneG4Es9YlbnWQ (org.apache.kafka.clients.Metadata:401)
[2022-12-08 11:08:47,135] INFO [Consumer clientId=consumer-connect-cluster-1, groupId=connect-cluster] Resetting the last seen epoch of partition connect-offsets-17 to 4 since the associated topicId changed from null to AybVz0y6SneG4Es9YlbnWQ (org.apache.kafka.clients.Metadata:401)
[2022-12-08 11:08:47,135] INFO [Consumer clientId=consumer-connect-cluster-1, groupId=connect-cluster] Resetting the last seen epoch of partition connect-offsets-3 to 5 since the associated topicId changed from null to AybVz0y6SneG4Es9YlbnWQ (org.apache.kafka.clients.Metadata:401)
[2022-12-08 11:08:47,135] INFO [Consumer clientId=consumer-connect-cluster-1, groupId=connect-cluster] Resetting the last seen epoch of partition connect-offsets-24 to 4 since the associated topicId changed from null to AybVz0y6SneG4Es9YlbnWQ (org.apache.kafka.clients.Metadata:401)
[2022-12-08 11:08:47,135] INFO [Consumer clientId=consumer-connect-cluster-1, groupId=connect-cluster] Resetting the last seen epoch of partition connect-offsets-23 to 4 since the associated topicId changed from null to AybVz0y6SneG4Es9YlbnWQ (org.apache.kafka.clients.Metadata:401)
[2022-12-08 11:08:47,135] INFO [Consumer clientId=consumer-connect-cluster-1, groupId=connect-cluster] Resetting the last seen epoch of partition connect-offsets-13 to 3 since the associated topicId changed from null to AybVz0y6SneG4Es9YlbnWQ (org.apache.kafka.clients.Metadata:401)
[2022-12-08 11:08:47,135] INFO [Consumer clientId=consumer-connect-cluster-1, groupId=connect-cluster] Resetting the last seen epoch of partition connect-offsets-18 to 4 since the associated topicId changed from null to AybVz0y6SneG4Es9YlbnWQ (org.apache.kafka.clients.Metadata:401)
[2022-12-08 11:08:47,135] INFO [Consumer clientId=consumer-connect-cluster-1, groupId=connect-cluster] Resetting the last seen epoch of partition connect-offsets-22 to 3 since the associated topicId changed from null to AybVz0y6SneG4Es9YlbnWQ (org.apache.kafka.clients.Metadata:401)
[2022-12-08 11:08:47,135] INFO [Consumer clientId=consumer-connect-cluster-1, groupId=connect-cluster] Resetting the last seen epoch of partition connect-offsets-8 to 4 since the associated topicId changed from null to AybVz0y6SneG4Es9YlbnWQ (org.apache.kafka.clients.Metadata:401)
[2022-12-08 11:08:47,136] INFO [Consumer clientId=consumer-connect-cluster-1, groupId=connect-cluster] Resetting the last seen epoch of partition connect-offsets-2 to 4 since the associated topicId changed from null to AybVz0y6SneG4Es9YlbnWQ (org.apache.kafka.clients.Metadata:401)
[2022-12-08 11:08:47,136] INFO [Consumer clientId=consumer-connect-cluster-1, groupId=connect-cluster] Resetting the last seen epoch of partition connect-offsets-12 to 4 since the associated topicId changed from null to AybVz0y6SneG4Es9YlbnWQ (org.apache.kafka.clients.Metadata:401)
[2022-12-08 11:08:47,136] INFO [Consumer clientId=consumer-connect-cluster-1, groupId=connect-cluster] Resetting the last seen epoch of partition connect-offsets-19 to 3 since the associated topicId changed from null to AybVz0y6SneG4Es9YlbnWQ (org.apache.kafka.clients.Metadata:401)
[2022-12-08 11:08:47,136] INFO [Consumer clientId=consumer-connect-cluster-1, groupId=connect-cluster] Resetting the last seen epoch of partition connect-offsets-14 to 4 since the associated topicId changed from null to AybVz0y6SneG4Es9YlbnWQ (org.apache.kafka.clients.Metadata:401)
[2022-12-08 11:08:47,136] INFO [Consumer clientId=consumer-connect-cluster-1, groupId=connect-cluster] Resetting the last seen epoch of partition connect-offsets-1 to 3 since the associated topicId changed from null to AybVz0y6SneG4Es9YlbnWQ (org.apache.kafka.clients.Metadata:401)
[2022-12-08 11:08:47,136] INFO [Consumer clientId=consumer-connect-cluster-1, groupId=connect-cluster] Resetting the last seen epoch of partition connect-offsets-6 to 4 since the associated topicId changed from null to AybVz0y6SneG4Es9YlbnWQ (org.apache.kafka.clients.Metadata:401)
[2022-12-08 11:08:47,136] INFO [Consumer clientId=consumer-connect-cluster-1, groupId=connect-cluster] Resetting the last seen epoch of partition connect-offsets-7 to 3 since the associated topicId changed from null to AybVz0y6SneG4Es9YlbnWQ (org.apache.kafka.clients.Metadata:401)
[2022-12-08 11:08:47,136] INFO [Consumer clientId=consumer-connect-cluster-1, groupId=connect-cluster] Resetting the last seen epoch of partition connect-offsets-21 to 5 since the associated topicId changed from null to AybVz0y6SneG4Es9YlbnWQ (org.apache.kafka.clients.Metadata:401)
[2022-12-08 11:08:47,144] INFO [Consumer clientId=consumer-connect-cluster-1, groupId=connect-cluster] Resetting offset for partition connect-offsets-9 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:29092 (id: 1 rack: null)], epoch=5}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2022-12-08 11:08:47,144] INFO [Consumer clientId=consumer-connect-cluster-1, groupId=connect-cluster] Resetting offset for partition connect-offsets-24 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:29092 (id: 1 rack: null)], epoch=4}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2022-12-08 11:08:47,145] INFO [Consumer clientId=consumer-connect-cluster-1, groupId=connect-cluster] Resetting offset for partition connect-offsets-12 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:29092 (id: 1 rack: null)], epoch=4}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2022-12-08 11:08:47,145] INFO [Consumer clientId=consumer-connect-cluster-1, groupId=connect-cluster] Resetting offset for partition connect-offsets-18 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:29092 (id: 1 rack: null)], epoch=4}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2022-12-08 11:08:47,145] INFO [Consumer clientId=consumer-connect-cluster-1, groupId=connect-cluster] Resetting offset for partition connect-offsets-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:29092 (id: 1 rack: null)], epoch=4}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2022-12-08 11:08:47,145] INFO [Consumer clientId=consumer-connect-cluster-1, groupId=connect-cluster] Resetting offset for partition connect-offsets-15 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:29092 (id: 1 rack: null)], epoch=5}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2022-12-08 11:08:47,145] INFO [Consumer clientId=consumer-connect-cluster-1, groupId=connect-cluster] Resetting offset for partition connect-offsets-6 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:29092 (id: 1 rack: null)], epoch=4}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2022-12-08 11:08:47,145] INFO [Consumer clientId=consumer-connect-cluster-1, groupId=connect-cluster] Resetting offset for partition connect-offsets-21 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:29092 (id: 1 rack: null)], epoch=5}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2022-12-08 11:08:47,145] INFO [Consumer clientId=consumer-connect-cluster-1, groupId=connect-cluster] Resetting offset for partition connect-offsets-3 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:29092 (id: 1 rack: null)], epoch=5}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2022-12-08 11:08:47,148] INFO [Consumer clientId=consumer-connect-cluster-1, groupId=connect-cluster] Resetting offset for partition connect-offsets-10 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:39092 (id: 2 rack: null)], epoch=3}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2022-12-08 11:08:47,148] INFO [Consumer clientId=consumer-connect-cluster-1, groupId=connect-cluster] Resetting offset for partition connect-offsets-7 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:39092 (id: 2 rack: null)], epoch=3}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2022-12-08 11:08:47,149] INFO [Consumer clientId=consumer-connect-cluster-1, groupId=connect-cluster] Resetting offset for partition connect-offsets-13 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:39092 (id: 2 rack: null)], epoch=3}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2022-12-08 11:08:47,149] INFO [Consumer clientId=consumer-connect-cluster-1, groupId=connect-cluster] Resetting offset for partition connect-offsets-1 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:39092 (id: 2 rack: null)], epoch=3}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2022-12-08 11:08:47,149] INFO [Consumer clientId=consumer-connect-cluster-1, groupId=connect-cluster] Resetting offset for partition connect-offsets-16 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:39092 (id: 2 rack: null)], epoch=3}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2022-12-08 11:08:47,149] INFO [Consumer clientId=consumer-connect-cluster-1, groupId=connect-cluster] Resetting offset for partition connect-offsets-22 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:39092 (id: 2 rack: null)], epoch=3}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2022-12-08 11:08:47,149] INFO [Consumer clientId=consumer-connect-cluster-1, groupId=connect-cluster] Resetting offset for partition connect-offsets-4 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:39092 (id: 2 rack: null)], epoch=3}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2022-12-08 11:08:47,149] INFO [Consumer clientId=consumer-connect-cluster-1, groupId=connect-cluster] Resetting offset for partition connect-offsets-19 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:39092 (id: 2 rack: null)], epoch=3}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2022-12-08 11:08:47,150] INFO [Consumer clientId=consumer-connect-cluster-1, groupId=connect-cluster] Resetting offset for partition connect-offsets-8 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:49092 (id: 3 rack: null)], epoch=4}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2022-12-08 11:08:47,150] INFO [Consumer clientId=consumer-connect-cluster-1, groupId=connect-cluster] Resetting offset for partition connect-offsets-23 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:49092 (id: 3 rack: null)], epoch=4}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2022-12-08 11:08:47,150] INFO [Consumer clientId=consumer-connect-cluster-1, groupId=connect-cluster] Resetting offset for partition connect-offsets-14 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:49092 (id: 3 rack: null)], epoch=4}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2022-12-08 11:08:47,150] INFO [Consumer clientId=consumer-connect-cluster-1, groupId=connect-cluster] Resetting offset for partition connect-offsets-11 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:49092 (id: 3 rack: null)], epoch=4}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2022-12-08 11:08:47,150] INFO [Consumer clientId=consumer-connect-cluster-1, groupId=connect-cluster] Resetting offset for partition connect-offsets-2 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:49092 (id: 3 rack: null)], epoch=4}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2022-12-08 11:08:47,150] INFO [Consumer clientId=consumer-connect-cluster-1, groupId=connect-cluster] Resetting offset for partition connect-offsets-17 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:49092 (id: 3 rack: null)], epoch=4}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2022-12-08 11:08:47,150] INFO [Consumer clientId=consumer-connect-cluster-1, groupId=connect-cluster] Resetting offset for partition connect-offsets-5 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:49092 (id: 3 rack: null)], epoch=4}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2022-12-08 11:08:47,150] INFO [Consumer clientId=consumer-connect-cluster-1, groupId=connect-cluster] Resetting offset for partition connect-offsets-20 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:49092 (id: 3 rack: null)], epoch=4}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2022-12-08 11:08:47,151] INFO Finished reading KafkaBasedLog for topic connect-offsets (org.apache.kafka.connect.util.KafkaBasedLog:206)
[2022-12-08 11:08:47,151] INFO Started KafkaBasedLog for topic connect-offsets (org.apache.kafka.connect.util.KafkaBasedLog:208)
[2022-12-08 11:08:47,151] INFO Finished reading offsets topic and starting KafkaOffsetBackingStore (org.apache.kafka.connect.storage.KafkaOffsetBackingStore:146)
[2022-12-08 11:08:47,152] INFO Worker started (org.apache.kafka.connect.runtime.Worker:198)
[2022-12-08 11:08:47,152] INFO Starting KafkaBasedLog with topic connect-status (org.apache.kafka.connect.util.KafkaBasedLog:166)
[2022-12-08 11:08:47,159] INFO ProducerConfig values: 
	acks = -1
	batch.size = 16384
	bootstrap.servers = [localhost:29092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-2
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	internal.auto.downgrade.txn.commit = false
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
 (org.apache.kafka.clients.producer.ProducerConfig:372)
[2022-12-08 11:08:47,162] WARN The configuration 'config.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:380)
[2022-12-08 11:08:47,162] WARN The configuration 'metrics.context.connect.group.id' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:380)
[2022-12-08 11:08:47,162] WARN The configuration 'group.id' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:380)
[2022-12-08 11:08:47,162] WARN The configuration 'status.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:380)
[2022-12-08 11:08:47,162] WARN The configuration 'rest.host.name' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:380)
[2022-12-08 11:08:47,162] WARN The configuration 'plugin.path' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:380)
[2022-12-08 11:08:47,163] WARN The configuration 'topic.creation.enable' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:380)
[2022-12-08 11:08:47,163] WARN The configuration 'config.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:380)
[2022-12-08 11:08:47,163] WARN The configuration 'rest.port' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:380)
[2022-12-08 11:08:47,163] WARN The configuration 'key.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:380)
[2022-12-08 11:08:47,163] WARN The configuration 'metrics.context.connect.kafka.cluster.id' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:380)
[2022-12-08 11:08:47,163] WARN The configuration 'status.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:380)
[2022-12-08 11:08:47,163] WARN The configuration 'value.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:380)
[2022-12-08 11:08:47,163] WARN The configuration 'offset.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:380)
[2022-12-08 11:08:47,163] WARN The configuration 'offset.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:380)
[2022-12-08 11:08:47,164] WARN The configuration 'value.converter' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:380)
[2022-12-08 11:08:47,164] WARN The configuration 'key.converter' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:380)
[2022-12-08 11:08:47,164] INFO Kafka version: 2.8.2 (org.apache.kafka.common.utils.AppInfoParser:119)
[2022-12-08 11:08:47,164] INFO Kafka commitId: 3146c6ff4a24cc24 (org.apache.kafka.common.utils.AppInfoParser:120)
[2022-12-08 11:08:47,164] INFO Kafka startTimeMs: 1670465327164 (org.apache.kafka.common.utils.AppInfoParser:121)
[2022-12-08 11:08:47,164] INFO ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:29092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-connect-cluster-2
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-cluster
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:372)
[2022-12-08 11:08:47,167] INFO [Producer clientId=producer-2] Cluster ID: AJw0mIIBTzmvGtlyebvsaQ (org.apache.kafka.clients.Metadata:287)
[2022-12-08 11:08:47,168] WARN The configuration 'config.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:380)
[2022-12-08 11:08:47,168] WARN The configuration 'metrics.context.connect.group.id' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:380)
[2022-12-08 11:08:47,168] WARN The configuration 'status.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:380)
[2022-12-08 11:08:47,168] WARN The configuration 'rest.host.name' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:380)
[2022-12-08 11:08:47,168] WARN The configuration 'plugin.path' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:380)
[2022-12-08 11:08:47,168] WARN The configuration 'topic.creation.enable' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:380)
[2022-12-08 11:08:47,168] WARN The configuration 'config.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:380)
[2022-12-08 11:08:47,168] WARN The configuration 'rest.port' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:380)
[2022-12-08 11:08:47,168] WARN The configuration 'key.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:380)
[2022-12-08 11:08:47,168] WARN The configuration 'metrics.context.connect.kafka.cluster.id' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:380)
[2022-12-08 11:08:47,168] WARN The configuration 'status.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:380)
[2022-12-08 11:08:47,168] WARN The configuration 'value.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:380)
[2022-12-08 11:08:47,168] WARN The configuration 'offset.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:380)
[2022-12-08 11:08:47,169] WARN The configuration 'offset.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:380)
[2022-12-08 11:08:47,169] WARN The configuration 'value.converter' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:380)
[2022-12-08 11:08:47,169] WARN The configuration 'key.converter' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:380)
[2022-12-08 11:08:47,169] INFO Kafka version: 2.8.2 (org.apache.kafka.common.utils.AppInfoParser:119)
[2022-12-08 11:08:47,169] INFO Kafka commitId: 3146c6ff4a24cc24 (org.apache.kafka.common.utils.AppInfoParser:120)
[2022-12-08 11:08:47,169] INFO Kafka startTimeMs: 1670465327169 (org.apache.kafka.common.utils.AppInfoParser:121)
[2022-12-08 11:08:47,174] INFO [Consumer clientId=consumer-connect-cluster-2, groupId=connect-cluster] Cluster ID: AJw0mIIBTzmvGtlyebvsaQ (org.apache.kafka.clients.Metadata:287)
[2022-12-08 11:08:47,175] INFO [Consumer clientId=consumer-connect-cluster-2, groupId=connect-cluster] Subscribed to partition(s): connect-status-0, connect-status-4, connect-status-1, connect-status-2, connect-status-3 (org.apache.kafka.clients.consumer.KafkaConsumer:1120)
[2022-12-08 11:08:47,175] INFO [Consumer clientId=consumer-connect-cluster-2, groupId=connect-cluster] Seeking to EARLIEST offset of partition connect-status-0 (org.apache.kafka.clients.consumer.internals.SubscriptionState:619)
[2022-12-08 11:08:47,175] INFO [Consumer clientId=consumer-connect-cluster-2, groupId=connect-cluster] Seeking to EARLIEST offset of partition connect-status-4 (org.apache.kafka.clients.consumer.internals.SubscriptionState:619)
[2022-12-08 11:08:47,175] INFO [Consumer clientId=consumer-connect-cluster-2, groupId=connect-cluster] Seeking to EARLIEST offset of partition connect-status-1 (org.apache.kafka.clients.consumer.internals.SubscriptionState:619)
[2022-12-08 11:08:47,175] INFO [Consumer clientId=consumer-connect-cluster-2, groupId=connect-cluster] Seeking to EARLIEST offset of partition connect-status-2 (org.apache.kafka.clients.consumer.internals.SubscriptionState:619)
[2022-12-08 11:08:47,175] INFO [Consumer clientId=consumer-connect-cluster-2, groupId=connect-cluster] Seeking to EARLIEST offset of partition connect-status-3 (org.apache.kafka.clients.consumer.internals.SubscriptionState:619)
[2022-12-08 11:08:47,185] INFO [Consumer clientId=consumer-connect-cluster-2, groupId=connect-cluster] Resetting the last seen epoch of partition connect-status-0 to 4 since the associated topicId changed from null to nhX-9DQnQl663vaWgRQrtw (org.apache.kafka.clients.Metadata:401)
[2022-12-08 11:08:47,185] INFO [Consumer clientId=consumer-connect-cluster-2, groupId=connect-cluster] Resetting the last seen epoch of partition connect-status-1 to 4 since the associated topicId changed from null to nhX-9DQnQl663vaWgRQrtw (org.apache.kafka.clients.Metadata:401)
[2022-12-08 11:08:47,186] INFO [Consumer clientId=consumer-connect-cluster-2, groupId=connect-cluster] Resetting the last seen epoch of partition connect-status-4 to 5 since the associated topicId changed from null to nhX-9DQnQl663vaWgRQrtw (org.apache.kafka.clients.Metadata:401)
[2022-12-08 11:08:47,186] INFO [Consumer clientId=consumer-connect-cluster-2, groupId=connect-cluster] Resetting the last seen epoch of partition connect-status-2 to 3 since the associated topicId changed from null to nhX-9DQnQl663vaWgRQrtw (org.apache.kafka.clients.Metadata:401)
[2022-12-08 11:08:47,186] INFO [Consumer clientId=consumer-connect-cluster-2, groupId=connect-cluster] Resetting the last seen epoch of partition connect-status-3 to 4 since the associated topicId changed from null to nhX-9DQnQl663vaWgRQrtw (org.apache.kafka.clients.Metadata:401)
[2022-12-08 11:08:47,190] INFO [Consumer clientId=consumer-connect-cluster-2, groupId=connect-cluster] Resetting offset for partition connect-status-2 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:39092 (id: 2 rack: null)], epoch=3}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2022-12-08 11:08:47,193] INFO [Consumer clientId=consumer-connect-cluster-2, groupId=connect-cluster] Resetting offset for partition connect-status-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:49092 (id: 3 rack: null)], epoch=4}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2022-12-08 11:08:47,194] INFO [Consumer clientId=consumer-connect-cluster-2, groupId=connect-cluster] Resetting offset for partition connect-status-3 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:49092 (id: 3 rack: null)], epoch=4}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2022-12-08 11:08:47,200] INFO [Consumer clientId=consumer-connect-cluster-2, groupId=connect-cluster] Resetting offset for partition connect-status-1 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:29092 (id: 1 rack: null)], epoch=4}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2022-12-08 11:08:47,200] INFO [Consumer clientId=consumer-connect-cluster-2, groupId=connect-cluster] Resetting offset for partition connect-status-4 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:29092 (id: 1 rack: null)], epoch=5}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2022-12-08 11:08:47,239] INFO Finished reading KafkaBasedLog for topic connect-status (org.apache.kafka.connect.util.KafkaBasedLog:206)
[2022-12-08 11:08:47,239] INFO Started KafkaBasedLog for topic connect-status (org.apache.kafka.connect.util.KafkaBasedLog:208)
[2022-12-08 11:08:47,240] INFO Starting KafkaConfigBackingStore (org.apache.kafka.connect.storage.KafkaConfigBackingStore:275)
[2022-12-08 11:08:47,240] INFO Starting KafkaBasedLog with topic connect-configs (org.apache.kafka.connect.util.KafkaBasedLog:166)
[2022-12-08 11:08:47,249] INFO ProducerConfig values: 
	acks = -1
	batch.size = 16384
	bootstrap.servers = [localhost:29092]
	buffer.memory = 33554432
	client.dns.lookup = use_all_dns_ips
	client.id = producer-3
	compression.type = none
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 2147483647
	enable.idempotence = false
	interceptor.classes = []
	internal.auto.downgrade.txn.commit = false
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 1
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metadata.max.idle.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
 (org.apache.kafka.clients.producer.ProducerConfig:372)
[2022-12-08 11:08:47,252] WARN The configuration 'config.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:380)
[2022-12-08 11:08:47,252] WARN The configuration 'metrics.context.connect.group.id' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:380)
[2022-12-08 11:08:47,252] WARN The configuration 'group.id' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:380)
[2022-12-08 11:08:47,252] WARN The configuration 'status.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:380)
[2022-12-08 11:08:47,252] WARN The configuration 'rest.host.name' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:380)
[2022-12-08 11:08:47,253] WARN The configuration 'plugin.path' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:380)
[2022-12-08 11:08:47,253] WARN The configuration 'topic.creation.enable' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:380)
[2022-12-08 11:08:47,253] WARN The configuration 'config.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:380)
[2022-12-08 11:08:47,253] WARN The configuration 'rest.port' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:380)
[2022-12-08 11:08:47,253] WARN The configuration 'key.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:380)
[2022-12-08 11:08:47,253] WARN The configuration 'metrics.context.connect.kafka.cluster.id' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:380)
[2022-12-08 11:08:47,253] WARN The configuration 'status.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:380)
[2022-12-08 11:08:47,261] WARN The configuration 'value.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:380)
[2022-12-08 11:08:47,261] WARN The configuration 'offset.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:380)
[2022-12-08 11:08:47,262] WARN The configuration 'offset.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:380)
[2022-12-08 11:08:47,262] WARN The configuration 'value.converter' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:380)
[2022-12-08 11:08:47,258] INFO [Producer clientId=producer-3] Cluster ID: AJw0mIIBTzmvGtlyebvsaQ (org.apache.kafka.clients.Metadata:287)
[2022-12-08 11:08:47,262] WARN The configuration 'key.converter' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:380)
[2022-12-08 11:08:47,262] INFO Kafka version: 2.8.2 (org.apache.kafka.common.utils.AppInfoParser:119)
[2022-12-08 11:08:47,262] INFO Kafka commitId: 3146c6ff4a24cc24 (org.apache.kafka.common.utils.AppInfoParser:120)
[2022-12-08 11:08:47,262] INFO Kafka startTimeMs: 1670465327262 (org.apache.kafka.common.utils.AppInfoParser:121)
[2022-12-08 11:08:47,263] INFO ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:29092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-connect-cluster-3
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-cluster
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:372)
[2022-12-08 11:08:47,265] WARN The configuration 'config.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:380)
[2022-12-08 11:08:47,265] WARN The configuration 'metrics.context.connect.group.id' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:380)
[2022-12-08 11:08:47,265] WARN The configuration 'status.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:380)
[2022-12-08 11:08:47,265] WARN The configuration 'rest.host.name' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:380)
[2022-12-08 11:08:47,266] WARN The configuration 'plugin.path' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:380)
[2022-12-08 11:08:47,266] WARN The configuration 'topic.creation.enable' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:380)
[2022-12-08 11:08:47,266] WARN The configuration 'config.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:380)
[2022-12-08 11:08:47,266] WARN The configuration 'rest.port' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:380)
[2022-12-08 11:08:47,266] WARN The configuration 'key.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:380)
[2022-12-08 11:08:47,266] WARN The configuration 'metrics.context.connect.kafka.cluster.id' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:380)
[2022-12-08 11:08:47,266] WARN The configuration 'status.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:380)
[2022-12-08 11:08:47,266] WARN The configuration 'value.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:380)
[2022-12-08 11:08:47,266] WARN The configuration 'offset.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:380)
[2022-12-08 11:08:47,266] WARN The configuration 'offset.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:380)
[2022-12-08 11:08:47,266] WARN The configuration 'value.converter' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:380)
[2022-12-08 11:08:47,266] WARN The configuration 'key.converter' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:380)
[2022-12-08 11:08:47,266] INFO Kafka version: 2.8.2 (org.apache.kafka.common.utils.AppInfoParser:119)
[2022-12-08 11:08:47,266] INFO Kafka commitId: 3146c6ff4a24cc24 (org.apache.kafka.common.utils.AppInfoParser:120)
[2022-12-08 11:08:47,266] INFO Kafka startTimeMs: 1670465327266 (org.apache.kafka.common.utils.AppInfoParser:121)
[2022-12-08 11:08:47,272] INFO [Consumer clientId=consumer-connect-cluster-3, groupId=connect-cluster] Cluster ID: AJw0mIIBTzmvGtlyebvsaQ (org.apache.kafka.clients.Metadata:287)
[2022-12-08 11:08:47,273] INFO [Consumer clientId=consumer-connect-cluster-3, groupId=connect-cluster] Subscribed to partition(s): connect-configs-0 (org.apache.kafka.clients.consumer.KafkaConsumer:1120)
[2022-12-08 11:08:47,273] INFO [Consumer clientId=consumer-connect-cluster-3, groupId=connect-cluster] Seeking to EARLIEST offset of partition connect-configs-0 (org.apache.kafka.clients.consumer.internals.SubscriptionState:619)
[2022-12-08 11:08:47,282] INFO [Consumer clientId=consumer-connect-cluster-3, groupId=connect-cluster] Resetting the last seen epoch of partition connect-configs-0 to 5 since the associated topicId changed from null to mi_nRLY3TG-sJC4K8Hk6_g (org.apache.kafka.clients.Metadata:401)
[2022-12-08 11:08:47,287] INFO [Consumer clientId=consumer-connect-cluster-3, groupId=connect-cluster] Resetting offset for partition connect-configs-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:29092 (id: 1 rack: null)], epoch=5}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2022-12-08 11:08:47,292] INFO Finished reading KafkaBasedLog for topic connect-configs (org.apache.kafka.connect.util.KafkaBasedLog:206)
[2022-12-08 11:08:47,293] INFO Started KafkaBasedLog for topic connect-configs (org.apache.kafka.connect.util.KafkaBasedLog:208)
[2022-12-08 11:08:47,293] INFO Started KafkaConfigBackingStore (org.apache.kafka.connect.storage.KafkaConfigBackingStore:290)
[2022-12-08 11:08:47,293] INFO [Worker clientId=connect-1, groupId=connect-cluster] Herder started (org.apache.kafka.connect.runtime.distributed.DistributedHerder:312)
[2022-12-08 11:08:47,298] INFO [Worker clientId=connect-1, groupId=connect-cluster] Resetting the last seen epoch of partition test-topic-0 to 0 since the associated topicId changed from null to WetbeyyhS0qxNan22VVG3g (org.apache.kafka.clients.Metadata:401)
[2022-12-08 11:08:47,298] INFO [Worker clientId=connect-1, groupId=connect-cluster] Resetting the last seen epoch of partition connect-configs-0 to 5 since the associated topicId changed from null to mi_nRLY3TG-sJC4K8Hk6_g (org.apache.kafka.clients.Metadata:401)
[2022-12-08 11:08:47,298] INFO [Worker clientId=connect-1, groupId=connect-cluster] Resetting the last seen epoch of partition fake-topic-1208-0 to 0 since the associated topicId changed from null to VTQtF8PeRR6zv5-DUyP4Lg (org.apache.kafka.clients.Metadata:401)
[2022-12-08 11:08:47,299] INFO [Worker clientId=connect-1, groupId=connect-cluster] Resetting the last seen epoch of partition connect-offsets-0 to 4 since the associated topicId changed from null to AybVz0y6SneG4Es9YlbnWQ (org.apache.kafka.clients.Metadata:401)
[2022-12-08 11:08:47,299] INFO [Worker clientId=connect-1, groupId=connect-cluster] Resetting the last seen epoch of partition connect-offsets-5 to 4 since the associated topicId changed from null to AybVz0y6SneG4Es9YlbnWQ (org.apache.kafka.clients.Metadata:401)
[2022-12-08 11:08:47,299] INFO [Worker clientId=connect-1, groupId=connect-cluster] Resetting the last seen epoch of partition connect-offsets-10 to 3 since the associated topicId changed from null to AybVz0y6SneG4Es9YlbnWQ (org.apache.kafka.clients.Metadata:401)
[2022-12-08 11:08:47,299] INFO [Worker clientId=connect-1, groupId=connect-cluster] Resetting the last seen epoch of partition connect-offsets-20 to 4 since the associated topicId changed from null to AybVz0y6SneG4Es9YlbnWQ (org.apache.kafka.clients.Metadata:401)
[2022-12-08 11:08:47,299] INFO [Worker clientId=connect-1, groupId=connect-cluster] Resetting the last seen epoch of partition connect-offsets-15 to 5 since the associated topicId changed from null to AybVz0y6SneG4Es9YlbnWQ (org.apache.kafka.clients.Metadata:401)
[2022-12-08 11:08:47,299] INFO [Worker clientId=connect-1, groupId=connect-cluster] Resetting the last seen epoch of partition connect-offsets-9 to 5 since the associated topicId changed from null to AybVz0y6SneG4Es9YlbnWQ (org.apache.kafka.clients.Metadata:401)
[2022-12-08 11:08:47,299] INFO [Worker clientId=connect-1, groupId=connect-cluster] Resetting the last seen epoch of partition connect-offsets-11 to 4 since the associated topicId changed from null to AybVz0y6SneG4Es9YlbnWQ (org.apache.kafka.clients.Metadata:401)
[2022-12-08 11:08:47,299] INFO [Worker clientId=connect-1, groupId=connect-cluster] Resetting the last seen epoch of partition connect-offsets-4 to 3 since the associated topicId changed from null to AybVz0y6SneG4Es9YlbnWQ (org.apache.kafka.clients.Metadata:401)
[2022-12-08 11:08:47,299] INFO [Worker clientId=connect-1, groupId=connect-cluster] Resetting the last seen epoch of partition connect-offsets-16 to 3 since the associated topicId changed from null to AybVz0y6SneG4Es9YlbnWQ (org.apache.kafka.clients.Metadata:401)
[2022-12-08 11:08:47,299] INFO [Worker clientId=connect-1, groupId=connect-cluster] Resetting the last seen epoch of partition connect-offsets-17 to 4 since the associated topicId changed from null to AybVz0y6SneG4Es9YlbnWQ (org.apache.kafka.clients.Metadata:401)
[2022-12-08 11:08:47,299] INFO [Worker clientId=connect-1, groupId=connect-cluster] Resetting the last seen epoch of partition connect-offsets-3 to 5 since the associated topicId changed from null to AybVz0y6SneG4Es9YlbnWQ (org.apache.kafka.clients.Metadata:401)
[2022-12-08 11:08:47,299] INFO [Worker clientId=connect-1, groupId=connect-cluster] Resetting the last seen epoch of partition connect-offsets-24 to 4 since the associated topicId changed from null to AybVz0y6SneG4Es9YlbnWQ (org.apache.kafka.clients.Metadata:401)
[2022-12-08 11:08:47,299] INFO [Worker clientId=connect-1, groupId=connect-cluster] Resetting the last seen epoch of partition connect-offsets-23 to 4 since the associated topicId changed from null to AybVz0y6SneG4Es9YlbnWQ (org.apache.kafka.clients.Metadata:401)
[2022-12-08 11:08:47,299] INFO [Worker clientId=connect-1, groupId=connect-cluster] Resetting the last seen epoch of partition connect-offsets-13 to 3 since the associated topicId changed from null to AybVz0y6SneG4Es9YlbnWQ (org.apache.kafka.clients.Metadata:401)
[2022-12-08 11:08:47,300] INFO [Worker clientId=connect-1, groupId=connect-cluster] Resetting the last seen epoch of partition connect-offsets-18 to 4 since the associated topicId changed from null to AybVz0y6SneG4Es9YlbnWQ (org.apache.kafka.clients.Metadata:401)
[2022-12-08 11:08:47,300] INFO [Worker clientId=connect-1, groupId=connect-cluster] Resetting the last seen epoch of partition connect-offsets-22 to 3 since the associated topicId changed from null to AybVz0y6SneG4Es9YlbnWQ (org.apache.kafka.clients.Metadata:401)
[2022-12-08 11:08:47,300] INFO [Worker clientId=connect-1, groupId=connect-cluster] Resetting the last seen epoch of partition connect-offsets-8 to 4 since the associated topicId changed from null to AybVz0y6SneG4Es9YlbnWQ (org.apache.kafka.clients.Metadata:401)
[2022-12-08 11:08:47,300] INFO [Worker clientId=connect-1, groupId=connect-cluster] Resetting the last seen epoch of partition connect-offsets-2 to 4 since the associated topicId changed from null to AybVz0y6SneG4Es9YlbnWQ (org.apache.kafka.clients.Metadata:401)
[2022-12-08 11:08:47,300] INFO [Worker clientId=connect-1, groupId=connect-cluster] Resetting the last seen epoch of partition connect-offsets-12 to 4 since the associated topicId changed from null to AybVz0y6SneG4Es9YlbnWQ (org.apache.kafka.clients.Metadata:401)
[2022-12-08 11:08:47,300] INFO [Worker clientId=connect-1, groupId=connect-cluster] Resetting the last seen epoch of partition connect-offsets-19 to 3 since the associated topicId changed from null to AybVz0y6SneG4Es9YlbnWQ (org.apache.kafka.clients.Metadata:401)
[2022-12-08 11:08:47,300] INFO [Worker clientId=connect-1, groupId=connect-cluster] Resetting the last seen epoch of partition connect-offsets-14 to 4 since the associated topicId changed from null to AybVz0y6SneG4Es9YlbnWQ (org.apache.kafka.clients.Metadata:401)
[2022-12-08 11:08:47,300] INFO [Worker clientId=connect-1, groupId=connect-cluster] Resetting the last seen epoch of partition connect-offsets-1 to 3 since the associated topicId changed from null to AybVz0y6SneG4Es9YlbnWQ (org.apache.kafka.clients.Metadata:401)
[2022-12-08 11:08:47,300] INFO [Worker clientId=connect-1, groupId=connect-cluster] Resetting the last seen epoch of partition connect-offsets-6 to 4 since the associated topicId changed from null to AybVz0y6SneG4Es9YlbnWQ (org.apache.kafka.clients.Metadata:401)
[2022-12-08 11:08:47,300] INFO [Worker clientId=connect-1, groupId=connect-cluster] Resetting the last seen epoch of partition connect-offsets-7 to 3 since the associated topicId changed from null to AybVz0y6SneG4Es9YlbnWQ (org.apache.kafka.clients.Metadata:401)
[2022-12-08 11:08:47,300] INFO [Worker clientId=connect-1, groupId=connect-cluster] Resetting the last seen epoch of partition connect-offsets-21 to 5 since the associated topicId changed from null to AybVz0y6SneG4Es9YlbnWQ (org.apache.kafka.clients.Metadata:401)
[2022-12-08 11:08:47,300] INFO [Worker clientId=connect-1, groupId=connect-cluster] Resetting the last seen epoch of partition __consumer_offsets-0 to 3 since the associated topicId changed from null to B_QAdRh3T5q2vg10PxO_PQ (org.apache.kafka.clients.Metadata:401)
[2022-12-08 11:08:47,301] INFO [Worker clientId=connect-1, groupId=connect-cluster] Resetting the last seen epoch of partition __consumer_offsets-10 to 4 since the associated topicId changed from null to B_QAdRh3T5q2vg10PxO_PQ (org.apache.kafka.clients.Metadata:401)
[2022-12-08 11:08:47,301] INFO [Worker clientId=connect-1, groupId=connect-cluster] Resetting the last seen epoch of partition __consumer_offsets-20 to 2 since the associated topicId changed from null to B_QAdRh3T5q2vg10PxO_PQ (org.apache.kafka.clients.Metadata:401)
[2022-12-08 11:08:47,301] INFO [Worker clientId=connect-1, groupId=connect-cluster] Resetting the last seen epoch of partition __consumer_offsets-40 to 4 since the associated topicId changed from null to B_QAdRh3T5q2vg10PxO_PQ (org.apache.kafka.clients.Metadata:401)
[2022-12-08 11:08:47,301] INFO [Worker clientId=connect-1, groupId=connect-cluster] Resetting the last seen epoch of partition __consumer_offsets-30 to 3 since the associated topicId changed from null to B_QAdRh3T5q2vg10PxO_PQ (org.apache.kafka.clients.Metadata:401)
[2022-12-08 11:08:47,301] INFO [Worker clientId=connect-1, groupId=connect-cluster] Resetting the last seen epoch of partition __consumer_offsets-9 to 3 since the associated topicId changed from null to B_QAdRh3T5q2vg10PxO_PQ (org.apache.kafka.clients.Metadata:401)
[2022-12-08 11:08:47,301] INFO [Worker clientId=connect-1, groupId=connect-cluster] Resetting the last seen epoch of partition __consumer_offsets-11 to 2 since the associated topicId changed from null to B_QAdRh3T5q2vg10PxO_PQ (org.apache.kafka.clients.Metadata:401)
[2022-12-08 11:08:47,301] INFO [Worker clientId=connect-1, groupId=connect-cluster] Resetting the last seen epoch of partition __consumer_offsets-31 to 4 since the associated topicId changed from null to B_QAdRh3T5q2vg10PxO_PQ (org.apache.kafka.clients.Metadata:401)
[2022-12-08 11:08:47,301] INFO [Worker clientId=connect-1, groupId=connect-cluster] Resetting the last seen epoch of partition __consumer_offsets-39 to 3 since the associated topicId changed from null to B_QAdRh3T5q2vg10PxO_PQ (org.apache.kafka.clients.Metadata:401)
[2022-12-08 11:08:47,301] INFO [Worker clientId=connect-1, groupId=connect-cluster] Resetting the last seen epoch of partition __consumer_offsets-13 to 4 since the associated topicId changed from null to B_QAdRh3T5q2vg10PxO_PQ (org.apache.kafka.clients.Metadata:401)
[2022-12-08 11:08:47,301] INFO [Worker clientId=connect-1, groupId=connect-cluster] Resetting the last seen epoch of partition __consumer_offsets-18 to 3 since the associated topicId changed from null to B_QAdRh3T5q2vg10PxO_PQ (org.apache.kafka.clients.Metadata:401)
[2022-12-08 11:08:47,301] INFO [Worker clientId=connect-1, groupId=connect-cluster] Resetting the last seen epoch of partition __consumer_offsets-22 to 4 since the associated topicId changed from null to B_QAdRh3T5q2vg10PxO_PQ (org.apache.kafka.clients.Metadata:401)
[2022-12-08 11:08:47,301] INFO [Worker clientId=connect-1, groupId=connect-cluster] Resetting the last seen epoch of partition __consumer_offsets-8 to 2 since the associated topicId changed from null to B_QAdRh3T5q2vg10PxO_PQ (org.apache.kafka.clients.Metadata:401)
[2022-12-08 11:08:47,301] INFO [Worker clientId=connect-1, groupId=connect-cluster] Resetting the last seen epoch of partition __consumer_offsets-32 to 2 since the associated topicId changed from null to B_QAdRh3T5q2vg10PxO_PQ (org.apache.kafka.clients.Metadata:401)
[2022-12-08 11:08:47,301] INFO [Worker clientId=connect-1, groupId=connect-cluster] Resetting the last seen epoch of partition __consumer_offsets-43 to 4 since the associated topicId changed from null to B_QAdRh3T5q2vg10PxO_PQ (org.apache.kafka.clients.Metadata:401)
[2022-12-08 11:08:47,302] INFO [Worker clientId=connect-1, groupId=connect-cluster] Resetting the last seen epoch of partition __consumer_offsets-29 to 2 since the associated topicId changed from null to B_QAdRh3T5q2vg10PxO_PQ (org.apache.kafka.clients.Metadata:401)
[2022-12-08 11:08:47,302] INFO [Worker clientId=connect-1, groupId=connect-cluster] Resetting the last seen epoch of partition __consumer_offsets-34 to 4 since the associated topicId changed from null to B_QAdRh3T5q2vg10PxO_PQ (org.apache.kafka.clients.Metadata:401)
[2022-12-08 11:08:47,302] INFO [Worker clientId=connect-1, groupId=connect-cluster] Resetting the last seen epoch of partition __consumer_offsets-1 to 4 since the associated topicId changed from null to B_QAdRh3T5q2vg10PxO_PQ (org.apache.kafka.clients.Metadata:401)
[2022-12-08 11:08:47,302] INFO [Worker clientId=connect-1, groupId=connect-cluster] Resetting the last seen epoch of partition __consumer_offsets-6 to 3 since the associated topicId changed from null to B_QAdRh3T5q2vg10PxO_PQ (org.apache.kafka.clients.Metadata:401)
[2022-12-08 11:08:47,302] INFO [Worker clientId=connect-1, groupId=connect-cluster] Resetting the last seen epoch of partition __consumer_offsets-41 to 2 since the associated topicId changed from null to B_QAdRh3T5q2vg10PxO_PQ (org.apache.kafka.clients.Metadata:401)
[2022-12-08 11:08:47,302] INFO [Worker clientId=connect-1, groupId=connect-cluster] Resetting the last seen epoch of partition __consumer_offsets-27 to 3 since the associated topicId changed from null to B_QAdRh3T5q2vg10PxO_PQ (org.apache.kafka.clients.Metadata:401)
[2022-12-08 11:08:47,302] INFO [Worker clientId=connect-1, groupId=connect-cluster] Resetting the last seen epoch of partition __consumer_offsets-48 to 3 since the associated topicId changed from null to B_QAdRh3T5q2vg10PxO_PQ (org.apache.kafka.clients.Metadata:401)
[2022-12-08 11:08:47,302] INFO [Worker clientId=connect-1, groupId=connect-cluster] Resetting the last seen epoch of partition __consumer_offsets-5 to 2 since the associated topicId changed from null to B_QAdRh3T5q2vg10PxO_PQ (org.apache.kafka.clients.Metadata:401)
[2022-12-08 11:08:47,302] INFO [Worker clientId=connect-1, groupId=connect-cluster] Resetting the last seen epoch of partition __consumer_offsets-15 to 3 since the associated topicId changed from null to B_QAdRh3T5q2vg10PxO_PQ (org.apache.kafka.clients.Metadata:401)
[2022-12-08 11:08:47,302] INFO [Worker clientId=connect-1, groupId=connect-cluster] Resetting the last seen epoch of partition __consumer_offsets-35 to 2 since the associated topicId changed from null to B_QAdRh3T5q2vg10PxO_PQ (org.apache.kafka.clients.Metadata:401)
[2022-12-08 11:08:47,302] INFO [Worker clientId=connect-1, groupId=connect-cluster] Resetting the last seen epoch of partition __consumer_offsets-25 to 4 since the associated topicId changed from null to B_QAdRh3T5q2vg10PxO_PQ (org.apache.kafka.clients.Metadata:401)
[2022-12-08 11:08:47,302] INFO [Worker clientId=connect-1, groupId=connect-cluster] Resetting the last seen epoch of partition __consumer_offsets-46 to 4 since the associated topicId changed from null to B_QAdRh3T5q2vg10PxO_PQ (org.apache.kafka.clients.Metadata:401)
[2022-12-08 11:08:47,302] INFO [Worker clientId=connect-1, groupId=connect-cluster] Resetting the last seen epoch of partition __consumer_offsets-26 to 2 since the associated topicId changed from null to B_QAdRh3T5q2vg10PxO_PQ (org.apache.kafka.clients.Metadata:401)
[2022-12-08 11:08:47,302] INFO [Worker clientId=connect-1, groupId=connect-cluster] Resetting the last seen epoch of partition __consumer_offsets-36 to 3 since the associated topicId changed from null to B_QAdRh3T5q2vg10PxO_PQ (org.apache.kafka.clients.Metadata:401)
[2022-12-08 11:08:47,302] INFO [Worker clientId=connect-1, groupId=connect-cluster] Resetting the last seen epoch of partition __consumer_offsets-44 to 2 since the associated topicId changed from null to B_QAdRh3T5q2vg10PxO_PQ (org.apache.kafka.clients.Metadata:401)
[2022-12-08 11:08:47,303] INFO [Worker clientId=connect-1, groupId=connect-cluster] Resetting the last seen epoch of partition __consumer_offsets-16 to 4 since the associated topicId changed from null to B_QAdRh3T5q2vg10PxO_PQ (org.apache.kafka.clients.Metadata:401)
[2022-12-08 11:08:47,303] INFO [Worker clientId=connect-1, groupId=connect-cluster] Resetting the last seen epoch of partition __consumer_offsets-37 to 4 since the associated topicId changed from null to B_QAdRh3T5q2vg10PxO_PQ (org.apache.kafka.clients.Metadata:401)
[2022-12-08 11:08:47,303] INFO [Worker clientId=connect-1, groupId=connect-cluster] Resetting the last seen epoch of partition __consumer_offsets-17 to 2 since the associated topicId changed from null to B_QAdRh3T5q2vg10PxO_PQ (org.apache.kafka.clients.Metadata:401)
[2022-12-08 11:08:47,303] INFO [Worker clientId=connect-1, groupId=connect-cluster] Resetting the last seen epoch of partition __consumer_offsets-45 to 3 since the associated topicId changed from null to B_QAdRh3T5q2vg10PxO_PQ (org.apache.kafka.clients.Metadata:401)
[2022-12-08 11:08:47,303] INFO [Worker clientId=connect-1, groupId=connect-cluster] Resetting the last seen epoch of partition __consumer_offsets-3 to 3 since the associated topicId changed from null to B_QAdRh3T5q2vg10PxO_PQ (org.apache.kafka.clients.Metadata:401)
[2022-12-08 11:08:47,303] INFO [Worker clientId=connect-1, groupId=connect-cluster] Resetting the last seen epoch of partition __consumer_offsets-24 to 3 since the associated topicId changed from null to B_QAdRh3T5q2vg10PxO_PQ (org.apache.kafka.clients.Metadata:401)
[2022-12-08 11:08:47,303] INFO [Worker clientId=connect-1, groupId=connect-cluster] Resetting the last seen epoch of partition __consumer_offsets-38 to 2 since the associated topicId changed from null to B_QAdRh3T5q2vg10PxO_PQ (org.apache.kafka.clients.Metadata:401)
[2022-12-08 11:08:47,303] INFO [Worker clientId=connect-1, groupId=connect-cluster] Resetting the last seen epoch of partition __consumer_offsets-33 to 3 since the associated topicId changed from null to B_QAdRh3T5q2vg10PxO_PQ (org.apache.kafka.clients.Metadata:401)
[2022-12-08 11:08:47,303] INFO [Worker clientId=connect-1, groupId=connect-cluster] Resetting the last seen epoch of partition __consumer_offsets-23 to 2 since the associated topicId changed from null to B_QAdRh3T5q2vg10PxO_PQ (org.apache.kafka.clients.Metadata:401)
[2022-12-08 11:08:47,303] INFO [Worker clientId=connect-1, groupId=connect-cluster] Resetting the last seen epoch of partition __consumer_offsets-28 to 4 since the associated topicId changed from null to B_QAdRh3T5q2vg10PxO_PQ (org.apache.kafka.clients.Metadata:401)
[2022-12-08 11:08:47,303] INFO [Worker clientId=connect-1, groupId=connect-cluster] Resetting the last seen epoch of partition __consumer_offsets-2 to 2 since the associated topicId changed from null to B_QAdRh3T5q2vg10PxO_PQ (org.apache.kafka.clients.Metadata:401)
[2022-12-08 11:08:47,303] INFO [Worker clientId=connect-1, groupId=connect-cluster] Resetting the last seen epoch of partition __consumer_offsets-12 to 3 since the associated topicId changed from null to B_QAdRh3T5q2vg10PxO_PQ (org.apache.kafka.clients.Metadata:401)
[2022-12-08 11:08:47,303] INFO [Worker clientId=connect-1, groupId=connect-cluster] Resetting the last seen epoch of partition __consumer_offsets-19 to 4 since the associated topicId changed from null to B_QAdRh3T5q2vg10PxO_PQ (org.apache.kafka.clients.Metadata:401)
[2022-12-08 11:08:47,303] INFO [Worker clientId=connect-1, groupId=connect-cluster] Resetting the last seen epoch of partition __consumer_offsets-14 to 2 since the associated topicId changed from null to B_QAdRh3T5q2vg10PxO_PQ (org.apache.kafka.clients.Metadata:401)
[2022-12-08 11:08:47,304] INFO [Worker clientId=connect-1, groupId=connect-cluster] Resetting the last seen epoch of partition __consumer_offsets-4 to 4 since the associated topicId changed from null to B_QAdRh3T5q2vg10PxO_PQ (org.apache.kafka.clients.Metadata:401)
[2022-12-08 11:08:47,304] INFO [Worker clientId=connect-1, groupId=connect-cluster] Resetting the last seen epoch of partition __consumer_offsets-47 to 2 since the associated topicId changed from null to B_QAdRh3T5q2vg10PxO_PQ (org.apache.kafka.clients.Metadata:401)
[2022-12-08 11:08:47,304] INFO [Worker clientId=connect-1, groupId=connect-cluster] Resetting the last seen epoch of partition __consumer_offsets-49 to 4 since the associated topicId changed from null to B_QAdRh3T5q2vg10PxO_PQ (org.apache.kafka.clients.Metadata:401)
[2022-12-08 11:08:47,304] INFO [Worker clientId=connect-1, groupId=connect-cluster] Resetting the last seen epoch of partition __consumer_offsets-42 to 3 since the associated topicId changed from null to B_QAdRh3T5q2vg10PxO_PQ (org.apache.kafka.clients.Metadata:401)
[2022-12-08 11:08:47,304] INFO [Worker clientId=connect-1, groupId=connect-cluster] Resetting the last seen epoch of partition __consumer_offsets-7 to 4 since the associated topicId changed from null to B_QAdRh3T5q2vg10PxO_PQ (org.apache.kafka.clients.Metadata:401)
[2022-12-08 11:08:47,304] INFO [Worker clientId=connect-1, groupId=connect-cluster] Resetting the last seen epoch of partition __consumer_offsets-21 to 3 since the associated topicId changed from null to B_QAdRh3T5q2vg10PxO_PQ (org.apache.kafka.clients.Metadata:401)
[2022-12-08 11:08:47,304] INFO [Worker clientId=connect-1, groupId=connect-cluster] Resetting the last seen epoch of partition fake-topic-000-0 to 0 since the associated topicId changed from null to UdPPaEyqRuKb4WFbRubR9g (org.apache.kafka.clients.Metadata:401)
[2022-12-08 11:08:47,304] INFO [Worker clientId=connect-1, groupId=connect-cluster] Resetting the last seen epoch of partition fake-topic20-0 to 2 since the associated topicId changed from null to FhDaBZOPTyG4doTWyCiDqw (org.apache.kafka.clients.Metadata:401)
[2022-12-08 11:08:47,304] INFO [Worker clientId=connect-1, groupId=connect-cluster] Resetting the last seen epoch of partition fake-topic20-5 to 4 since the associated topicId changed from null to FhDaBZOPTyG4doTWyCiDqw (org.apache.kafka.clients.Metadata:401)
[2022-12-08 11:08:47,304] INFO [Worker clientId=connect-1, groupId=connect-cluster] Resetting the last seen epoch of partition fake-topic20-10 to 3 since the associated topicId changed from null to FhDaBZOPTyG4doTWyCiDqw (org.apache.kafka.clients.Metadata:401)
[2022-12-08 11:08:47,304] INFO [Worker clientId=connect-1, groupId=connect-cluster] Resetting the last seen epoch of partition fake-topic20-8 to 4 since the associated topicId changed from null to FhDaBZOPTyG4doTWyCiDqw (org.apache.kafka.clients.Metadata:401)
[2022-12-08 11:08:47,304] INFO [Worker clientId=connect-1, groupId=connect-cluster] Resetting the last seen epoch of partition fake-topic20-2 to 4 since the associated topicId changed from null to FhDaBZOPTyG4doTWyCiDqw (org.apache.kafka.clients.Metadata:401)
[2022-12-08 11:08:47,304] INFO [Worker clientId=connect-1, groupId=connect-cluster] Resetting the last seen epoch of partition fake-topic20-9 to 2 since the associated topicId changed from null to FhDaBZOPTyG4doTWyCiDqw (org.apache.kafka.clients.Metadata:401)
[2022-12-08 11:08:47,304] INFO [Worker clientId=connect-1, groupId=connect-cluster] Resetting the last seen epoch of partition fake-topic20-11 to 4 since the associated topicId changed from null to FhDaBZOPTyG4doTWyCiDqw (org.apache.kafka.clients.Metadata:401)
[2022-12-08 11:08:47,305] INFO [Worker clientId=connect-1, groupId=connect-cluster] Resetting the last seen epoch of partition fake-topic20-4 to 3 since the associated topicId changed from null to FhDaBZOPTyG4doTWyCiDqw (org.apache.kafka.clients.Metadata:401)
[2022-12-08 11:08:47,305] INFO [Worker clientId=connect-1, groupId=connect-cluster] Resetting the last seen epoch of partition fake-topic20-1 to 3 since the associated topicId changed from null to FhDaBZOPTyG4doTWyCiDqw (org.apache.kafka.clients.Metadata:401)
[2022-12-08 11:08:47,305] INFO [Worker clientId=connect-1, groupId=connect-cluster] Resetting the last seen epoch of partition fake-topic20-6 to 2 since the associated topicId changed from null to FhDaBZOPTyG4doTWyCiDqw (org.apache.kafka.clients.Metadata:401)
[2022-12-08 11:08:47,305] INFO [Worker clientId=connect-1, groupId=connect-cluster] Resetting the last seen epoch of partition fake-topic20-7 to 3 since the associated topicId changed from null to FhDaBZOPTyG4doTWyCiDqw (org.apache.kafka.clients.Metadata:401)
[2022-12-08 11:08:47,305] INFO [Worker clientId=connect-1, groupId=connect-cluster] Resetting the last seen epoch of partition fake-topic20-3 to 2 since the associated topicId changed from null to FhDaBZOPTyG4doTWyCiDqw (org.apache.kafka.clients.Metadata:401)
[2022-12-08 11:08:47,305] INFO [Worker clientId=connect-1, groupId=connect-cluster] Resetting the last seen epoch of partition connect-status-0 to 4 since the associated topicId changed from null to nhX-9DQnQl663vaWgRQrtw (org.apache.kafka.clients.Metadata:401)
[2022-12-08 11:08:47,305] INFO [Worker clientId=connect-1, groupId=connect-cluster] Resetting the last seen epoch of partition connect-status-4 to 5 since the associated topicId changed from null to nhX-9DQnQl663vaWgRQrtw (org.apache.kafka.clients.Metadata:401)
[2022-12-08 11:08:47,305] INFO [Worker clientId=connect-1, groupId=connect-cluster] Resetting the last seen epoch of partition connect-status-1 to 4 since the associated topicId changed from null to nhX-9DQnQl663vaWgRQrtw (org.apache.kafka.clients.Metadata:401)
[2022-12-08 11:08:47,305] INFO [Worker clientId=connect-1, groupId=connect-cluster] Resetting the last seen epoch of partition connect-status-2 to 3 since the associated topicId changed from null to nhX-9DQnQl663vaWgRQrtw (org.apache.kafka.clients.Metadata:401)
[2022-12-08 11:08:47,305] INFO [Worker clientId=connect-1, groupId=connect-cluster] Resetting the last seen epoch of partition connect-status-3 to 4 since the associated topicId changed from null to nhX-9DQnQl663vaWgRQrtw (org.apache.kafka.clients.Metadata:401)
[2022-12-08 11:08:47,305] INFO [Worker clientId=connect-1, groupId=connect-cluster] Resetting the last seen epoch of partition fake-topic-0 to 2 since the associated topicId changed from null to 6DSc2ry3SueSfVKrnCC_Jw (org.apache.kafka.clients.Metadata:401)
[2022-12-08 11:08:47,306] INFO [Worker clientId=connect-1, groupId=connect-cluster] Cluster ID: AJw0mIIBTzmvGtlyebvsaQ (org.apache.kafka.clients.Metadata:287)
[2022-12-08 11:08:47,306] INFO [Worker clientId=connect-1, groupId=connect-cluster] Discovered group coordinator localhost:29092 (id: 2147483646 rack: null) (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:850)
[2022-12-08 11:08:47,308] INFO [Worker clientId=connect-1, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:221)
[2022-12-08 11:08:47,308] INFO [Worker clientId=connect-1, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:540)
[2022-12-08 11:08:47,324] INFO [Worker clientId=connect-1, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:540)
[2022-12-08 11:08:47,476] INFO Started o.e.j.s.ServletContextHandler@392a04e7{/,null,AVAILABLE} (org.eclipse.jetty.server.handler.ContextHandler:921)
[2022-12-08 11:08:47,476] INFO REST resources initialized; server is started and ready to handle requests (org.apache.kafka.connect.runtime.rest.RestServer:319)
[2022-12-08 11:08:47,476] INFO Kafka Connect started (org.apache.kafka.connect.runtime.Connect:57)
[2022-12-08 11:08:50,335] INFO [Worker clientId=connect-1, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=1, memberId='connect-1-959a7585-201e-4793-9430-47c0590d4ddb', protocol='sessioned'} (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:596)
[2022-12-08 11:08:50,359] INFO [Worker clientId=connect-1, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=1, memberId='connect-1-959a7585-201e-4793-9430-47c0590d4ddb', protocol='sessioned'} (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:760)
[2022-12-08 11:08:50,360] INFO [Worker clientId=connect-1, groupId=connect-cluster] Joined group at generation 1 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-1-959a7585-201e-4793-9430-47c0590d4ddb', leaderUrl='http://localhost:8083/', offset=6, connectorIds=[mongo-sink-fake-topic-1], taskIds=[mongo-sink-fake-topic-1-0, mongo-sink-fake-topic-1-1], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1699)
[2022-12-08 11:08:50,361] WARN [Worker clientId=connect-1, groupId=connect-cluster] Catching up to assignment's config offset. (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1119)
[2022-12-08 11:08:50,361] INFO [Worker clientId=connect-1, groupId=connect-cluster] Current config state offset -1 is behind group assignment 6, reading to end of config log (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1183)
[2022-12-08 11:08:50,365] INFO [Worker clientId=connect-1, groupId=connect-cluster] Finished reading to end of log and updated config snapshot, new config log offset: 6 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1190)
[2022-12-08 11:08:50,365] INFO [Worker clientId=connect-1, groupId=connect-cluster] Starting connectors and tasks using config offset 6 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1244)
[2022-12-08 11:08:50,366] INFO [Worker clientId=connect-1, groupId=connect-cluster] Starting task mongo-sink-fake-topic-1-0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1286)
[2022-12-08 11:08:50,366] INFO [Worker clientId=connect-1, groupId=connect-cluster] Starting task mongo-sink-fake-topic-1-1 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1286)
[2022-12-08 11:08:50,366] INFO [Worker clientId=connect-1, groupId=connect-cluster] Starting connector mongo-sink-fake-topic-1 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1321)
[2022-12-08 11:08:50,370] INFO Creating task mongo-sink-fake-topic-1-0 (org.apache.kafka.connect.runtime.Worker:505)
[2022-12-08 11:08:50,370] INFO Creating connector mongo-sink-fake-topic-1 of type com.mongodb.kafka.connect.MongoSinkConnector (org.apache.kafka.connect.runtime.Worker:271)
[2022-12-08 11:08:50,370] INFO Creating task mongo-sink-fake-topic-1-1 (org.apache.kafka.connect.runtime.Worker:505)
[2022-12-08 11:08:50,372] INFO ConnectorConfig values: 
	config.action.reload = restart
	connector.class = com.mongodb.kafka.connect.MongoSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = mongo-sink-fake-topic-1
	predicates = []
	tasks.max = 2
	transforms = []
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig:372)
[2022-12-08 11:08:50,372] INFO ConnectorConfig values: 
	config.action.reload = restart
	connector.class = com.mongodb.kafka.connect.MongoSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = mongo-sink-fake-topic-1
	predicates = []
	tasks.max = 2
	transforms = []
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig:372)
[2022-12-08 11:08:50,372] INFO SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = com.mongodb.kafka.connect.MongoSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = mongo-sink-fake-topic-1
	predicates = []
	tasks.max = 2
	topics = [fake-topic]
	topics.regex = 
	transforms = []
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:372)
[2022-12-08 11:08:50,374] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = com.mongodb.kafka.connect.MongoSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = mongo-sink-fake-topic-1
	predicates = []
	tasks.max = 2
	transforms = []
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2022-12-08 11:08:50,374] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = com.mongodb.kafka.connect.MongoSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = mongo-sink-fake-topic-1
	predicates = []
	tasks.max = 2
	topics = [fake-topic]
	topics.regex = 
	transforms = []
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2022-12-08 11:08:50,374] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = com.mongodb.kafka.connect.MongoSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = mongo-sink-fake-topic-1
	predicates = []
	tasks.max = 2
	transforms = []
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2022-12-08 11:08:50,376] INFO TaskConfig values: 
	task.class = class com.mongodb.kafka.connect.sink.MongoSinkTask
 (org.apache.kafka.connect.runtime.TaskConfig:372)
[2022-12-08 11:08:50,376] INFO TaskConfig values: 
	task.class = class com.mongodb.kafka.connect.sink.MongoSinkTask
 (org.apache.kafka.connect.runtime.TaskConfig:372)
[2022-12-08 11:08:50,376] INFO Instantiated task mongo-sink-fake-topic-1-0 with version 1.8.1 of type com.mongodb.kafka.connect.sink.MongoSinkTask (org.apache.kafka.connect.runtime.Worker:520)
[2022-12-08 11:08:50,376] INFO Instantiated task mongo-sink-fake-topic-1-1 with version 1.8.1 of type com.mongodb.kafka.connect.sink.MongoSinkTask (org.apache.kafka.connect.runtime.Worker:520)
[2022-12-08 11:08:50,377] INFO StringConverterConfig values: 
	converter.encoding = UTF8
	converter.type = key
 (org.apache.kafka.connect.storage.StringConverterConfig:372)
[2022-12-08 11:08:50,377] INFO StringConverterConfig values: 
	converter.encoding = UTF8
	converter.type = key
 (org.apache.kafka.connect.storage.StringConverterConfig:372)
[2022-12-08 11:08:50,377] INFO JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:372)
[2022-12-08 11:08:50,377] INFO JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:372)
[2022-12-08 11:08:50,377] INFO Set up the key converter class org.apache.kafka.connect.storage.StringConverter for task mongo-sink-fake-topic-1-0 using the connector config (org.apache.kafka.connect.runtime.Worker:535)
[2022-12-08 11:08:50,377] INFO Instantiated connector mongo-sink-fake-topic-1 with version 1.8.1 of type class com.mongodb.kafka.connect.MongoSinkConnector (org.apache.kafka.connect.runtime.Worker:281)
[2022-12-08 11:08:50,377] INFO Set up the key converter class org.apache.kafka.connect.storage.StringConverter for task mongo-sink-fake-topic-1-1 using the connector config (org.apache.kafka.connect.runtime.Worker:535)
[2022-12-08 11:08:50,377] INFO Set up the value converter class org.apache.kafka.connect.json.JsonConverter for task mongo-sink-fake-topic-1-0 using the connector config (org.apache.kafka.connect.runtime.Worker:541)
[2022-12-08 11:08:50,378] INFO Set up the value converter class org.apache.kafka.connect.json.JsonConverter for task mongo-sink-fake-topic-1-1 using the connector config (org.apache.kafka.connect.runtime.Worker:541)
[2022-12-08 11:08:50,378] INFO Set up the header converter class org.apache.kafka.connect.storage.SimpleHeaderConverter for task mongo-sink-fake-topic-1-0 using the worker config (org.apache.kafka.connect.runtime.Worker:546)
[2022-12-08 11:08:50,378] INFO Finished creating connector mongo-sink-fake-topic-1 (org.apache.kafka.connect.runtime.Worker:306)
[2022-12-08 11:08:50,378] INFO Set up the header converter class org.apache.kafka.connect.storage.SimpleHeaderConverter for task mongo-sink-fake-topic-1-1 using the worker config (org.apache.kafka.connect.runtime.Worker:546)
[2022-12-08 11:08:50,382] INFO Initializing: org.apache.kafka.connect.runtime.TransformationChain{} (org.apache.kafka.connect.runtime.Worker:626)
[2022-12-08 11:08:50,382] INFO Initializing: org.apache.kafka.connect.runtime.TransformationChain{} (org.apache.kafka.connect.runtime.Worker:626)
[2022-12-08 11:08:50,383] INFO SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = com.mongodb.kafka.connect.MongoSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = mongo-sink-fake-topic-1
	predicates = []
	tasks.max = 2
	topics = [fake-topic]
	topics.regex = 
	transforms = []
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:372)
[2022-12-08 11:08:50,383] INFO SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = com.mongodb.kafka.connect.MongoSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = mongo-sink-fake-topic-1
	predicates = []
	tasks.max = 2
	topics = [fake-topic]
	topics.regex = 
	transforms = []
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:372)
[2022-12-08 11:08:50,383] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = com.mongodb.kafka.connect.MongoSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = mongo-sink-fake-topic-1
	predicates = []
	tasks.max = 2
	topics = [fake-topic]
	topics.regex = 
	transforms = []
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2022-12-08 11:08:50,383] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = com.mongodb.kafka.connect.MongoSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = mongo-sink-fake-topic-1
	predicates = []
	tasks.max = 2
	topics = [fake-topic]
	topics.regex = 
	transforms = []
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2022-12-08 11:08:50,388] INFO ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:29092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = connector-consumer-mongo-sink-fake-topic-1-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-mongo-sink-fake-topic-1
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:372)
[2022-12-08 11:08:50,388] INFO ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:29092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = connector-consumer-mongo-sink-fake-topic-1-0
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-mongo-sink-fake-topic-1
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:372)
[2022-12-08 11:08:50,394] WARN The configuration 'metrics.context.connect.kafka.cluster.id' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:380)
[2022-12-08 11:08:50,395] INFO [Producer clientId=producer-2] Resetting the last seen epoch of partition connect-status-0 to 4 since the associated topicId changed from null to nhX-9DQnQl663vaWgRQrtw (org.apache.kafka.clients.Metadata:401)
[2022-12-08 11:08:50,394] WARN The configuration 'metrics.context.connect.kafka.cluster.id' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:380)
[2022-12-08 11:08:50,396] INFO [Producer clientId=producer-2] Resetting the last seen epoch of partition connect-status-4 to 5 since the associated topicId changed from null to nhX-9DQnQl663vaWgRQrtw (org.apache.kafka.clients.Metadata:401)
[2022-12-08 11:08:50,395] WARN The configuration 'metrics.context.connect.group.id' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:380)
[2022-12-08 11:08:50,396] INFO [Producer clientId=producer-2] Resetting the last seen epoch of partition connect-status-1 to 4 since the associated topicId changed from null to nhX-9DQnQl663vaWgRQrtw (org.apache.kafka.clients.Metadata:401)
[2022-12-08 11:08:50,396] WARN The configuration 'metrics.context.connect.group.id' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:380)
[2022-12-08 11:08:50,396] INFO [Producer clientId=producer-2] Resetting the last seen epoch of partition connect-status-2 to 3 since the associated topicId changed from null to nhX-9DQnQl663vaWgRQrtw (org.apache.kafka.clients.Metadata:401)
[2022-12-08 11:08:50,396] INFO Kafka version: 2.8.2 (org.apache.kafka.common.utils.AppInfoParser:119)
[2022-12-08 11:08:50,396] INFO [Producer clientId=producer-2] Resetting the last seen epoch of partition connect-status-3 to 4 since the associated topicId changed from null to nhX-9DQnQl663vaWgRQrtw (org.apache.kafka.clients.Metadata:401)
[2022-12-08 11:08:50,396] INFO Kafka commitId: 3146c6ff4a24cc24 (org.apache.kafka.common.utils.AppInfoParser:120)
[2022-12-08 11:08:50,396] INFO Kafka startTimeMs: 1670465330396 (org.apache.kafka.common.utils.AppInfoParser:121)
[2022-12-08 11:08:50,397] INFO Kafka version: 2.8.2 (org.apache.kafka.common.utils.AppInfoParser:119)
[2022-12-08 11:08:50,397] INFO Kafka commitId: 3146c6ff4a24cc24 (org.apache.kafka.common.utils.AppInfoParser:120)
[2022-12-08 11:08:50,397] INFO Kafka startTimeMs: 1670465330396 (org.apache.kafka.common.utils.AppInfoParser:121)
[2022-12-08 11:08:50,405] INFO [Worker clientId=connect-1, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1272)
[2022-12-08 11:08:50,407] INFO [Consumer clientId=connector-consumer-mongo-sink-fake-topic-1-0, groupId=connect-mongo-sink-fake-topic-1] Subscribed to topic(s): fake-topic (org.apache.kafka.clients.consumer.KafkaConsumer:965)
[2022-12-08 11:08:50,407] INFO [Consumer clientId=connector-consumer-mongo-sink-fake-topic-1-1, groupId=connect-mongo-sink-fake-topic-1] Subscribed to topic(s): fake-topic (org.apache.kafka.clients.consumer.KafkaConsumer:965)
[2022-12-08 11:08:50,407] INFO Starting MongoDB sink task (com.mongodb.kafka.connect.sink.MongoSinkTask:64)
[2022-12-08 11:08:50,407] INFO Starting MongoDB sink task (com.mongodb.kafka.connect.sink.MongoSinkTask:64)
[2022-12-08 11:08:50,412] INFO [Producer clientId=producer-3] Resetting the last seen epoch of partition connect-configs-0 to 5 since the associated topicId changed from null to mi_nRLY3TG-sJC4K8Hk6_g (org.apache.kafka.clients.Metadata:401)
[2022-12-08 11:08:50,425] INFO [Worker clientId=connect-1, groupId=connect-cluster] Session key updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1587)
[2022-12-08 11:08:50,434] INFO SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = com.mongodb.kafka.connect.MongoSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = mongo-sink-fake-topic-1
	predicates = []
	tasks.max = 2
	topics = [fake-topic]
	topics.regex = 
	transforms = []
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:372)
[2022-12-08 11:08:50,435] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = com.mongodb.kafka.connect.MongoSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = mongo-sink-fake-topic-1
	predicates = []
	tasks.max = 2
	topics = [fake-topic]
	topics.regex = 
	transforms = []
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2022-12-08 11:08:50,456] INFO MongoSinkTopicConfig values: 
	bulk.write.ordered = true
	change.data.capture.handler = 
	collection = fake-topic
	database = kafka-1
	delete.on.null.values = false
	document.id.strategy = com.mongodb.kafka.connect.sink.processor.id.strategy.BsonOidStrategy
	document.id.strategy.overwrite.existing = false
	document.id.strategy.partial.key.projection.list = 
	document.id.strategy.partial.key.projection.type = 
	document.id.strategy.partial.value.projection.list = 
	document.id.strategy.partial.value.projection.type = 
	document.id.strategy.uuid.format = string
	errors.log.enable = false
	errors.tolerance = none
	field.renamer.mapping = []
	field.renamer.regexp = []
	key.projection.list = 
	key.projection.type = none
	max.batch.size = 0
	mongo.errors.log.enable = false
	mongo.errors.tolerance = none
	namespace.mapper = com.mongodb.kafka.connect.sink.namespace.mapping.DefaultNamespaceMapper
	namespace.mapper.error.if.invalid = false
	namespace.mapper.key.collection.field = 
	namespace.mapper.key.database.field = 
	namespace.mapper.value.collection.field = 
	namespace.mapper.value.database.field = 
	post.processor.chain = [com.mongodb.kafka.connect.sink.processor.DocumentIdAdder]
	rate.limiting.every.n = 0
	rate.limiting.timeout = 0
	timeseries.expire.after.seconds = 0
	timeseries.granularity = 
	timeseries.metafield = 
	timeseries.timefield = 
	timeseries.timefield.auto.convert = false
	timeseries.timefield.auto.convert.date.format = yyyy-MM-dd[['T'][ ]][HH:mm:ss[[.][SSSSSS][SSS]][ ]VV[ ]'['VV']'][HH:mm:ss[[.][SSSSSS][SSS]][ ]X][HH:mm:ss[[.][SSSSSS][SSS]]]
	timeseries.timefield.auto.convert.locale.language.tag = 
	topic = fake-topic
	value.projection.list = 
	value.projection.type = none
	writemodel.strategy = com.mongodb.kafka.connect.sink.writemodel.strategy.DefaultWriteModelStrategy
 (com.mongodb.kafka.connect.sink.MongoSinkTopicConfig:372)
[2022-12-08 11:08:50,456] INFO MongoSinkTopicConfig values: 
	bulk.write.ordered = true
	change.data.capture.handler = 
	collection = fake-topic
	database = kafka-1
	delete.on.null.values = false
	document.id.strategy = com.mongodb.kafka.connect.sink.processor.id.strategy.BsonOidStrategy
	document.id.strategy.overwrite.existing = false
	document.id.strategy.partial.key.projection.list = 
	document.id.strategy.partial.key.projection.type = 
	document.id.strategy.partial.value.projection.list = 
	document.id.strategy.partial.value.projection.type = 
	document.id.strategy.uuid.format = string
	errors.log.enable = false
	errors.tolerance = none
	field.renamer.mapping = []
	field.renamer.regexp = []
	key.projection.list = 
	key.projection.type = none
	max.batch.size = 0
	mongo.errors.log.enable = false
	mongo.errors.tolerance = none
	namespace.mapper = com.mongodb.kafka.connect.sink.namespace.mapping.DefaultNamespaceMapper
	namespace.mapper.error.if.invalid = false
	namespace.mapper.key.collection.field = 
	namespace.mapper.key.database.field = 
	namespace.mapper.value.collection.field = 
	namespace.mapper.value.database.field = 
	post.processor.chain = [com.mongodb.kafka.connect.sink.processor.DocumentIdAdder]
	rate.limiting.every.n = 0
	rate.limiting.timeout = 0
	timeseries.expire.after.seconds = 0
	timeseries.granularity = 
	timeseries.metafield = 
	timeseries.timefield = 
	timeseries.timefield.auto.convert = false
	timeseries.timefield.auto.convert.date.format = yyyy-MM-dd[['T'][ ]][HH:mm:ss[[.][SSSSSS][SSS]][ ]VV[ ]'['VV']'][HH:mm:ss[[.][SSSSSS][SSS]][ ]X][HH:mm:ss[[.][SSSSSS][SSS]]]
	timeseries.timefield.auto.convert.locale.language.tag = 
	topic = fake-topic
	value.projection.list = 
	value.projection.type = none
	writemodel.strategy = com.mongodb.kafka.connect.sink.writemodel.strategy.DefaultWriteModelStrategy
 (com.mongodb.kafka.connect.sink.MongoSinkTopicConfig:372)
[2022-12-08 11:08:50,518] INFO MongoClient with metadata {"driver": {"name": "mongo-java-driver|sync|mongo-kafka|sink", "version": "4.7.2|1.8.1"}, "os": {"type": "Darwin", "name": "Mac OS X", "architecture": "x86_64", "version": "10.16"}, "platform": "Java/Oracle Corporation/1.8.0_152-b16"} created with settings MongoClientSettings{readPreference=primary, writeConcern=WriteConcern{w=null, wTimeout=null ms, journal=null}, retryWrites=true, retryReads=true, readConcern=ReadConcern{level=null}, credential=null, streamFactoryFactory=null, commandListeners=[], codecRegistry=ProvidersCodecRegistry{codecProviders=[ValueCodecProvider{}, BsonValueCodecProvider{}, DBRefCodecProvider{}, DBObjectCodecProvider{}, DocumentCodecProvider{}, IterableCodecProvider{}, MapCodecProvider{}, GeoJsonCodecProvider{}, GridFSFileCodecProvider{}, Jsr310CodecProvider{}, JsonObjectCodecProvider{}, BsonCodecProvider{}, EnumCodecProvider{}, com.mongodb.Jep395RecordCodecProvider@4bd8f76b]}, clusterSettings={hosts=[localhost:27017], srvServiceName=mongodb, mode=SINGLE, requiredClusterType=UNKNOWN, requiredReplicaSetName='null', serverSelector='null', clusterListeners='[]', serverSelectionTimeout='30000 ms', localThreshold='30000 ms'}, socketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=0, receiveBufferSize=0, sendBufferSize=0}, heartbeatSocketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=10000, receiveBufferSize=0, sendBufferSize=0}, connectionPoolSettings=ConnectionPoolSettings{maxSize=100, minSize=0, maxWaitTimeMS=120000, maxConnectionLifeTimeMS=0, maxConnectionIdleTimeMS=0, maintenanceInitialDelayMS=0, maintenanceFrequencyMS=60000, connectionPoolListeners=[], maxConnecting=2}, serverSettings=ServerSettings{heartbeatFrequencyMS=10000, minHeartbeatFrequencyMS=500, serverListeners='[]', serverMonitorListeners='[]'}, sslSettings=SslSettings{enabled=false, invalidHostNameAllowed=false, context=null}, applicationName='null', compressorList=[], uuidRepresentation=UNSPECIFIED, serverApi=null, autoEncryptionSettings=null, contextProvider=null} (org.mongodb.driver.client:71)
[2022-12-08 11:08:50,518] INFO MongoClient with metadata {"driver": {"name": "mongo-java-driver|sync|mongo-kafka|sink", "version": "4.7.2|1.8.1"}, "os": {"type": "Darwin", "name": "Mac OS X", "architecture": "x86_64", "version": "10.16"}, "platform": "Java/Oracle Corporation/1.8.0_152-b16"} created with settings MongoClientSettings{readPreference=primary, writeConcern=WriteConcern{w=null, wTimeout=null ms, journal=null}, retryWrites=true, retryReads=true, readConcern=ReadConcern{level=null}, credential=null, streamFactoryFactory=null, commandListeners=[], codecRegistry=ProvidersCodecRegistry{codecProviders=[ValueCodecProvider{}, BsonValueCodecProvider{}, DBRefCodecProvider{}, DBObjectCodecProvider{}, DocumentCodecProvider{}, IterableCodecProvider{}, MapCodecProvider{}, GeoJsonCodecProvider{}, GridFSFileCodecProvider{}, Jsr310CodecProvider{}, JsonObjectCodecProvider{}, BsonCodecProvider{}, EnumCodecProvider{}, com.mongodb.Jep395RecordCodecProvider@4bd8f76b]}, clusterSettings={hosts=[localhost:27017], srvServiceName=mongodb, mode=SINGLE, requiredClusterType=UNKNOWN, requiredReplicaSetName='null', serverSelector='null', clusterListeners='[]', serverSelectionTimeout='30000 ms', localThreshold='30000 ms'}, socketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=0, receiveBufferSize=0, sendBufferSize=0}, heartbeatSocketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=10000, receiveBufferSize=0, sendBufferSize=0}, connectionPoolSettings=ConnectionPoolSettings{maxSize=100, minSize=0, maxWaitTimeMS=120000, maxConnectionLifeTimeMS=0, maxConnectionIdleTimeMS=0, maintenanceInitialDelayMS=0, maintenanceFrequencyMS=60000, connectionPoolListeners=[], maxConnecting=2}, serverSettings=ServerSettings{heartbeatFrequencyMS=10000, minHeartbeatFrequencyMS=500, serverListeners='[]', serverMonitorListeners='[]'}, sslSettings=SslSettings{enabled=false, invalidHostNameAllowed=false, context=null}, applicationName='null', compressorList=[], uuidRepresentation=UNSPECIFIED, serverApi=null, autoEncryptionSettings=null, contextProvider=null} (org.mongodb.driver.client:71)
[2022-12-08 11:08:50,520] INFO Errant record reporter not configured. (com.mongodb.kafka.connect.sink.MongoSinkTask:129)
[2022-12-08 11:08:50,520] INFO Errant record reporter not configured. (com.mongodb.kafka.connect.sink.MongoSinkTask:129)
[2022-12-08 11:08:50,528] INFO WorkerSinkTask{id=mongo-sink-fake-topic-1-0} Sink task finished initialization and start (org.apache.kafka.connect.runtime.WorkerSinkTask:310)
[2022-12-08 11:08:50,529] INFO WorkerSinkTask{id=mongo-sink-fake-topic-1-0} Executing sink task (org.apache.kafka.connect.runtime.WorkerSinkTask:196)
[2022-12-08 11:08:50,529] WARN MBean name conflict com.mongodb.kafka.connect:type=sink-task-metrics,task=sink-task-1 (com.mongodb.kafka.connect.util.jmx.internal.MBeanServerUtils:75)
javax.management.InstanceAlreadyExistsException: com.mongodb.kafka.connect:type=sink-task-metrics,task=sink-task-1
	at com.sun.jmx.mbeanserver.Repository.addMBean(Repository.java:437)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerWithRepository(DefaultMBeanServerInterceptor.java:1898)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerDynamicMBean(DefaultMBeanServerInterceptor.java:966)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerObject(DefaultMBeanServerInterceptor.java:900)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBean(DefaultMBeanServerInterceptor.java:324)
	at com.sun.jmx.mbeanserver.JmxMBeanServer.registerMBean(JmxMBeanServer.java:522)
	at com.mongodb.kafka.connect.util.jmx.internal.MBeanServerUtils.registerMBean(MBeanServerUtils.java:72)
	at com.mongodb.kafka.connect.util.jmx.internal.MongoMBean.register(MongoMBean.java:151)
	at com.mongodb.kafka.connect.sink.StartedMongoSinkTask.<init>(StartedMongoSinkTask.java:72)
	at com.mongodb.kafka.connect.sink.MongoSinkTask.start(MongoSinkTask.java:72)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.initializeAndStart(WorkerSinkTask.java:309)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:186)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:237)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
[2022-12-08 11:08:50,532] INFO WorkerSinkTask{id=mongo-sink-fake-topic-1-1} Sink task finished initialization and start (org.apache.kafka.connect.runtime.WorkerSinkTask:310)
[2022-12-08 11:08:50,534] INFO WorkerSinkTask{id=mongo-sink-fake-topic-1-1} Executing sink task (org.apache.kafka.connect.runtime.WorkerSinkTask:196)
[2022-12-08 11:08:50,535] INFO Opened connection [connectionId{localValue:1, serverValue:17}] to localhost:27017 (org.mongodb.driver.connection:71)
[2022-12-08 11:08:50,535] INFO Opened connection [connectionId{localValue:4, serverValue:20}] to localhost:27017 (org.mongodb.driver.connection:71)
[2022-12-08 11:08:50,536] INFO Opened connection [connectionId{localValue:2, serverValue:19}] to localhost:27017 (org.mongodb.driver.connection:71)
[2022-12-08 11:08:50,535] INFO Opened connection [connectionId{localValue:3, serverValue:18}] to localhost:27017 (org.mongodb.driver.connection:71)
[2022-12-08 11:08:50,536] INFO Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=13, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=19140398} (org.mongodb.driver.cluster:71)
[2022-12-08 11:08:50,536] INFO Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=13, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=19114953} (org.mongodb.driver.cluster:71)
[2022-12-08 11:08:50,538] INFO [Consumer clientId=connector-consumer-mongo-sink-fake-topic-1-0, groupId=connect-mongo-sink-fake-topic-1] Resetting the last seen epoch of partition fake-topic-0 to 2 since the associated topicId changed from null to 6DSc2ry3SueSfVKrnCC_Jw (org.apache.kafka.clients.Metadata:401)
[2022-12-08 11:08:50,538] INFO [Consumer clientId=connector-consumer-mongo-sink-fake-topic-1-0, groupId=connect-mongo-sink-fake-topic-1] Cluster ID: AJw0mIIBTzmvGtlyebvsaQ (org.apache.kafka.clients.Metadata:287)
[2022-12-08 11:08:50,538] INFO [Consumer clientId=connector-consumer-mongo-sink-fake-topic-1-0, groupId=connect-mongo-sink-fake-topic-1] Discovered group coordinator localhost:39092 (id: 2147483645 rack: null) (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:850)
[2022-12-08 11:08:50,539] INFO [Consumer clientId=connector-consumer-mongo-sink-fake-topic-1-0, groupId=connect-mongo-sink-fake-topic-1] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:540)
[2022-12-08 11:08:50,542] INFO [Consumer clientId=connector-consumer-mongo-sink-fake-topic-1-1, groupId=connect-mongo-sink-fake-topic-1] Resetting the last seen epoch of partition fake-topic-0 to 2 since the associated topicId changed from null to 6DSc2ry3SueSfVKrnCC_Jw (org.apache.kafka.clients.Metadata:401)
[2022-12-08 11:08:50,542] INFO [Consumer clientId=connector-consumer-mongo-sink-fake-topic-1-1, groupId=connect-mongo-sink-fake-topic-1] Cluster ID: AJw0mIIBTzmvGtlyebvsaQ (org.apache.kafka.clients.Metadata:287)
[2022-12-08 11:08:50,542] INFO [Consumer clientId=connector-consumer-mongo-sink-fake-topic-1-1, groupId=connect-mongo-sink-fake-topic-1] Discovered group coordinator localhost:39092 (id: 2147483645 rack: null) (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:850)
[2022-12-08 11:08:50,543] INFO [Consumer clientId=connector-consumer-mongo-sink-fake-topic-1-1, groupId=connect-mongo-sink-fake-topic-1] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:540)
[2022-12-08 11:08:50,549] INFO [Consumer clientId=connector-consumer-mongo-sink-fake-topic-1-1, groupId=connect-mongo-sink-fake-topic-1] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:540)
[2022-12-08 11:08:50,550] INFO [Consumer clientId=connector-consumer-mongo-sink-fake-topic-1-0, groupId=connect-mongo-sink-fake-topic-1] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:540)
[2022-12-08 11:08:53,554] INFO [Consumer clientId=connector-consumer-mongo-sink-fake-topic-1-1, groupId=connect-mongo-sink-fake-topic-1] Successfully joined group with generation Generation{generationId=3, memberId='connector-consumer-mongo-sink-fake-topic-1-1-493f8917-6bdb-4aa2-beda-5798f9df1e7f', protocol='range'} (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:596)
[2022-12-08 11:08:53,554] INFO [Consumer clientId=connector-consumer-mongo-sink-fake-topic-1-0, groupId=connect-mongo-sink-fake-topic-1] Successfully joined group with generation Generation{generationId=3, memberId='connector-consumer-mongo-sink-fake-topic-1-0-32984c18-ae5d-454a-bcf1-bd61479f276e', protocol='range'} (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:596)
[2022-12-08 11:08:53,557] INFO [Consumer clientId=connector-consumer-mongo-sink-fake-topic-1-1, groupId=connect-mongo-sink-fake-topic-1] Finished assignment for group at generation 3: {connector-consumer-mongo-sink-fake-topic-1-1-493f8917-6bdb-4aa2-beda-5798f9df1e7f=Assignment(partitions=[]), connector-consumer-mongo-sink-fake-topic-1-0-32984c18-ae5d-454a-bcf1-bd61479f276e=Assignment(partitions=[fake-topic-0])} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:652)
[2022-12-08 11:08:53,565] INFO [Consumer clientId=connector-consumer-mongo-sink-fake-topic-1-1, groupId=connect-mongo-sink-fake-topic-1] Successfully synced group in generation Generation{generationId=3, memberId='connector-consumer-mongo-sink-fake-topic-1-1-493f8917-6bdb-4aa2-beda-5798f9df1e7f', protocol='range'} (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:760)
[2022-12-08 11:08:53,565] INFO [Consumer clientId=connector-consumer-mongo-sink-fake-topic-1-1, groupId=connect-mongo-sink-fake-topic-1] Notifying assignor about the new Assignment(partitions=[]) (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:279)
[2022-12-08 11:08:53,565] INFO [Consumer clientId=connector-consumer-mongo-sink-fake-topic-1-1, groupId=connect-mongo-sink-fake-topic-1] Adding newly assigned partitions:  (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:291)
[2022-12-08 11:08:53,565] INFO [Consumer clientId=connector-consumer-mongo-sink-fake-topic-1-0, groupId=connect-mongo-sink-fake-topic-1] Successfully synced group in generation Generation{generationId=3, memberId='connector-consumer-mongo-sink-fake-topic-1-0-32984c18-ae5d-454a-bcf1-bd61479f276e', protocol='range'} (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:760)
[2022-12-08 11:08:53,566] INFO [Consumer clientId=connector-consumer-mongo-sink-fake-topic-1-0, groupId=connect-mongo-sink-fake-topic-1] Notifying assignor about the new Assignment(partitions=[fake-topic-0]) (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:279)
[2022-12-08 11:08:53,566] INFO [Consumer clientId=connector-consumer-mongo-sink-fake-topic-1-0, groupId=connect-mongo-sink-fake-topic-1] Adding newly assigned partitions: fake-topic-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:291)
[2022-12-08 11:08:53,573] INFO [Consumer clientId=connector-consumer-mongo-sink-fake-topic-1-0, groupId=connect-mongo-sink-fake-topic-1] Setting offset for partition fake-topic-0 to the committed offset FetchPosition{offset=1874, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:39092 (id: 2 rack: null)], epoch=2}} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:846)
[2022-12-08 11:13:18,787] INFO MongoSinkTopicConfig values: 
	bulk.write.ordered = true
	change.data.capture.handler = 
	collection = 
	database = kafka-1
	delete.on.null.values = false
	document.id.strategy = com.mongodb.kafka.connect.sink.processor.id.strategy.BsonOidStrategy
	document.id.strategy.overwrite.existing = false
	document.id.strategy.partial.key.projection.list = 
	document.id.strategy.partial.key.projection.type = 
	document.id.strategy.partial.value.projection.list = 
	document.id.strategy.partial.value.projection.type = 
	document.id.strategy.uuid.format = string
	errors.log.enable = false
	errors.tolerance = none
	field.renamer.mapping = []
	field.renamer.regexp = []
	key.projection.list = 
	key.projection.type = none
	max.batch.size = 0
	mongo.errors.log.enable = false
	mongo.errors.tolerance = none
	namespace.mapper = com.mongodb.kafka.connect.sink.namespace.mapping.DefaultNamespaceMapper
	namespace.mapper.error.if.invalid = false
	namespace.mapper.key.collection.field = 
	namespace.mapper.key.database.field = 
	namespace.mapper.value.collection.field = 
	namespace.mapper.value.database.field = 
	post.processor.chain = [com.mongodb.kafka.connect.sink.processor.DocumentIdAdder]
	rate.limiting.every.n = 0
	rate.limiting.timeout = 0
	timeseries.expire.after.seconds = 0
	timeseries.granularity = 
	timeseries.metafield = 
	timeseries.timefield = 
	timeseries.timefield.auto.convert = false
	timeseries.timefield.auto.convert.date.format = yyyy-MM-dd[['T'][ ]][HH:mm:ss[[.][SSSSSS][SSS]][ ]VV[ ]'['VV']'][HH:mm:ss[[.][SSSSSS][SSS]][ ]X][HH:mm:ss[[.][SSSSSS][SSS]]]
	timeseries.timefield.auto.convert.locale.language.tag = 
	topic = fake-topic-1208
	value.projection.list = 
	value.projection.type = none
	writemodel.strategy = com.mongodb.kafka.connect.sink.writemodel.strategy.DefaultWriteModelStrategy
 (com.mongodb.kafka.connect.sink.MongoSinkTopicConfig:372)
[2022-12-08 11:13:18,790] INFO MongoSinkTopicConfig values: 
	bulk.write.ordered = true
	change.data.capture.handler = 
	collection = 
	database = kafka-1
	delete.on.null.values = false
	document.id.strategy = com.mongodb.kafka.connect.sink.processor.id.strategy.BsonOidStrategy
	document.id.strategy.overwrite.existing = false
	document.id.strategy.partial.key.projection.list = 
	document.id.strategy.partial.key.projection.type = 
	document.id.strategy.partial.value.projection.list = 
	document.id.strategy.partial.value.projection.type = 
	document.id.strategy.uuid.format = string
	errors.log.enable = false
	errors.tolerance = none
	field.renamer.mapping = []
	field.renamer.regexp = []
	key.projection.list = 
	key.projection.type = none
	max.batch.size = 0
	mongo.errors.log.enable = false
	mongo.errors.tolerance = none
	namespace.mapper = com.mongodb.kafka.connect.sink.namespace.mapping.DefaultNamespaceMapper
	namespace.mapper.error.if.invalid = false
	namespace.mapper.key.collection.field = 
	namespace.mapper.key.database.field = 
	namespace.mapper.value.collection.field = 
	namespace.mapper.value.database.field = 
	post.processor.chain = [com.mongodb.kafka.connect.sink.processor.DocumentIdAdder]
	rate.limiting.every.n = 0
	rate.limiting.timeout = 0
	timeseries.expire.after.seconds = 0
	timeseries.granularity = 
	timeseries.metafield = 
	timeseries.timefield = 
	timeseries.timefield.auto.convert = false
	timeseries.timefield.auto.convert.date.format = yyyy-MM-dd[['T'][ ]][HH:mm:ss[[.][SSSSSS][SSS]][ ]VV[ ]'['VV']'][HH:mm:ss[[.][SSSSSS][SSS]][ ]X][HH:mm:ss[[.][SSSSSS][SSS]]]
	timeseries.timefield.auto.convert.locale.language.tag = 
	topic = fake-topic-1208
	value.projection.list = 
	value.projection.type = none
	writemodel.strategy = com.mongodb.kafka.connect.sink.writemodel.strategy.DefaultWriteModelStrategy
 (com.mongodb.kafka.connect.sink.MongoSinkTopicConfig:372)
[2022-12-08 11:13:18,799] INFO MongoClient with metadata {"driver": {"name": "mongo-java-driver|sync", "version": "4.7.2"}, "os": {"type": "Darwin", "name": "Mac OS X", "architecture": "x86_64", "version": "10.16"}, "platform": "Java/Oracle Corporation/1.8.0_152-b16"} created with settings MongoClientSettings{readPreference=primary, writeConcern=WriteConcern{w=null, wTimeout=null ms, journal=null}, retryWrites=true, retryReads=true, readConcern=ReadConcern{level=null}, credential=null, streamFactoryFactory=null, commandListeners=[], codecRegistry=ProvidersCodecRegistry{codecProviders=[ValueCodecProvider{}, BsonValueCodecProvider{}, DBRefCodecProvider{}, DBObjectCodecProvider{}, DocumentCodecProvider{}, IterableCodecProvider{}, MapCodecProvider{}, GeoJsonCodecProvider{}, GridFSFileCodecProvider{}, Jsr310CodecProvider{}, JsonObjectCodecProvider{}, BsonCodecProvider{}, EnumCodecProvider{}, com.mongodb.Jep395RecordCodecProvider@4bd8f76b]}, clusterSettings={hosts=[localhost:27017], srvServiceName=mongodb, mode=SINGLE, requiredClusterType=UNKNOWN, requiredReplicaSetName='null', serverSelector='null', clusterListeners='[com.mongodb.kafka.connect.util.ConnectionValidator$1@5c206418]', serverSelectionTimeout='30000 ms', localThreshold='30000 ms'}, socketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=0, receiveBufferSize=0, sendBufferSize=0}, heartbeatSocketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=10000, receiveBufferSize=0, sendBufferSize=0}, connectionPoolSettings=ConnectionPoolSettings{maxSize=100, minSize=0, maxWaitTimeMS=120000, maxConnectionLifeTimeMS=0, maxConnectionIdleTimeMS=0, maintenanceInitialDelayMS=0, maintenanceFrequencyMS=60000, connectionPoolListeners=[], maxConnecting=2}, serverSettings=ServerSettings{heartbeatFrequencyMS=10000, minHeartbeatFrequencyMS=500, serverListeners='[]', serverMonitorListeners='[]'}, sslSettings=SslSettings{enabled=false, invalidHostNameAllowed=false, context=null}, applicationName='null', compressorList=[], uuidRepresentation=UNSPECIFIED, serverApi=null, autoEncryptionSettings=null, contextProvider=null} (org.mongodb.driver.client:71)
[2022-12-08 11:13:18,800] INFO Opened connection [connectionId{localValue:5, serverValue:25}] to localhost:27017 (org.mongodb.driver.connection:71)
[2022-12-08 11:13:18,800] INFO Opened connection [connectionId{localValue:6, serverValue:26}] to localhost:27017 (org.mongodb.driver.connection:71)
[2022-12-08 11:13:18,800] INFO Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=13, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=735090} (org.mongodb.driver.cluster:71)
[2022-12-08 11:13:18,806] INFO AbstractConfig values: 
 (org.apache.kafka.common.config.AbstractConfig:372)
[2022-12-08 11:13:54,222] INFO MongoSinkTopicConfig values: 
	bulk.write.ordered = true
	change.data.capture.handler = 
	collection = 
	database = kafka-1
	delete.on.null.values = false
	document.id.strategy = com.mongodb.kafka.connect.sink.processor.id.strategy.BsonOidStrategy
	document.id.strategy.overwrite.existing = false
	document.id.strategy.partial.key.projection.list = 
	document.id.strategy.partial.key.projection.type = 
	document.id.strategy.partial.value.projection.list = 
	document.id.strategy.partial.value.projection.type = 
	document.id.strategy.uuid.format = string
	errors.log.enable = false
	errors.tolerance = none
	field.renamer.mapping = []
	field.renamer.regexp = []
	key.projection.list = 
	key.projection.type = none
	max.batch.size = 0
	mongo.errors.log.enable = false
	mongo.errors.tolerance = none
	namespace.mapper = com.mongodb.kafka.connect.sink.namespace.mapping.DefaultNamespaceMapper
	namespace.mapper.error.if.invalid = false
	namespace.mapper.key.collection.field = 
	namespace.mapper.key.database.field = 
	namespace.mapper.value.collection.field = 
	namespace.mapper.value.database.field = 
	post.processor.chain = [com.mongodb.kafka.connect.sink.processor.DocumentIdAdder]
	rate.limiting.every.n = 0
	rate.limiting.timeout = 0
	timeseries.expire.after.seconds = 0
	timeseries.granularity = 
	timeseries.metafield = 
	timeseries.timefield = 
	timeseries.timefield.auto.convert = false
	timeseries.timefield.auto.convert.date.format = yyyy-MM-dd[['T'][ ]][HH:mm:ss[[.][SSSSSS][SSS]][ ]VV[ ]'['VV']'][HH:mm:ss[[.][SSSSSS][SSS]][ ]X][HH:mm:ss[[.][SSSSSS][SSS]]]
	timeseries.timefield.auto.convert.locale.language.tag = 
	topic = fake-topic-1208
	value.projection.list = 
	value.projection.type = none
	writemodel.strategy = com.mongodb.kafka.connect.sink.writemodel.strategy.DefaultWriteModelStrategy
 (com.mongodb.kafka.connect.sink.MongoSinkTopicConfig:372)
[2022-12-08 11:13:54,223] INFO MongoSinkTopicConfig values: 
	bulk.write.ordered = true
	change.data.capture.handler = 
	collection = 
	database = kafka-1
	delete.on.null.values = false
	document.id.strategy = com.mongodb.kafka.connect.sink.processor.id.strategy.BsonOidStrategy
	document.id.strategy.overwrite.existing = false
	document.id.strategy.partial.key.projection.list = 
	document.id.strategy.partial.key.projection.type = 
	document.id.strategy.partial.value.projection.list = 
	document.id.strategy.partial.value.projection.type = 
	document.id.strategy.uuid.format = string
	errors.log.enable = false
	errors.tolerance = none
	field.renamer.mapping = []
	field.renamer.regexp = []
	key.projection.list = 
	key.projection.type = none
	max.batch.size = 0
	mongo.errors.log.enable = false
	mongo.errors.tolerance = none
	namespace.mapper = com.mongodb.kafka.connect.sink.namespace.mapping.DefaultNamespaceMapper
	namespace.mapper.error.if.invalid = false
	namespace.mapper.key.collection.field = 
	namespace.mapper.key.database.field = 
	namespace.mapper.value.collection.field = 
	namespace.mapper.value.database.field = 
	post.processor.chain = [com.mongodb.kafka.connect.sink.processor.DocumentIdAdder]
	rate.limiting.every.n = 0
	rate.limiting.timeout = 0
	timeseries.expire.after.seconds = 0
	timeseries.granularity = 
	timeseries.metafield = 
	timeseries.timefield = 
	timeseries.timefield.auto.convert = false
	timeseries.timefield.auto.convert.date.format = yyyy-MM-dd[['T'][ ]][HH:mm:ss[[.][SSSSSS][SSS]][ ]VV[ ]'['VV']'][HH:mm:ss[[.][SSSSSS][SSS]][ ]X][HH:mm:ss[[.][SSSSSS][SSS]]]
	timeseries.timefield.auto.convert.locale.language.tag = 
	topic = fake-topic-1208
	value.projection.list = 
	value.projection.type = none
	writemodel.strategy = com.mongodb.kafka.connect.sink.writemodel.strategy.DefaultWriteModelStrategy
 (com.mongodb.kafka.connect.sink.MongoSinkTopicConfig:372)
[2022-12-08 11:13:54,224] INFO MongoClient with metadata {"driver": {"name": "mongo-java-driver|sync", "version": "4.7.2"}, "os": {"type": "Darwin", "name": "Mac OS X", "architecture": "x86_64", "version": "10.16"}, "platform": "Java/Oracle Corporation/1.8.0_152-b16"} created with settings MongoClientSettings{readPreference=primary, writeConcern=WriteConcern{w=null, wTimeout=null ms, journal=null}, retryWrites=true, retryReads=true, readConcern=ReadConcern{level=null}, credential=null, streamFactoryFactory=null, commandListeners=[], codecRegistry=ProvidersCodecRegistry{codecProviders=[ValueCodecProvider{}, BsonValueCodecProvider{}, DBRefCodecProvider{}, DBObjectCodecProvider{}, DocumentCodecProvider{}, IterableCodecProvider{}, MapCodecProvider{}, GeoJsonCodecProvider{}, GridFSFileCodecProvider{}, Jsr310CodecProvider{}, JsonObjectCodecProvider{}, BsonCodecProvider{}, EnumCodecProvider{}, com.mongodb.Jep395RecordCodecProvider@4bd8f76b]}, clusterSettings={hosts=[localhost:27017], srvServiceName=mongodb, mode=SINGLE, requiredClusterType=UNKNOWN, requiredReplicaSetName='null', serverSelector='null', clusterListeners='[com.mongodb.kafka.connect.util.ConnectionValidator$1@15eb679c]', serverSelectionTimeout='30000 ms', localThreshold='30000 ms'}, socketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=0, receiveBufferSize=0, sendBufferSize=0}, heartbeatSocketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=10000, receiveBufferSize=0, sendBufferSize=0}, connectionPoolSettings=ConnectionPoolSettings{maxSize=100, minSize=0, maxWaitTimeMS=120000, maxConnectionLifeTimeMS=0, maxConnectionIdleTimeMS=0, maintenanceInitialDelayMS=0, maintenanceFrequencyMS=60000, connectionPoolListeners=[], maxConnecting=2}, serverSettings=ServerSettings{heartbeatFrequencyMS=10000, minHeartbeatFrequencyMS=500, serverListeners='[]', serverMonitorListeners='[]'}, sslSettings=SslSettings{enabled=false, invalidHostNameAllowed=false, context=null}, applicationName='null', compressorList=[], uuidRepresentation=UNSPECIFIED, serverApi=null, autoEncryptionSettings=null, contextProvider=null} (org.mongodb.driver.client:71)
[2022-12-08 11:13:54,225] INFO Opened connection [connectionId{localValue:7, serverValue:27}] to localhost:27017 (org.mongodb.driver.connection:71)
[2022-12-08 11:13:54,225] INFO Opened connection [connectionId{localValue:8, serverValue:28}] to localhost:27017 (org.mongodb.driver.connection:71)
[2022-12-08 11:13:54,226] INFO Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=13, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=678477} (org.mongodb.driver.cluster:71)
[2022-12-08 11:13:54,227] INFO AbstractConfig values: 
 (org.apache.kafka.common.config.AbstractConfig:372)
[2022-12-08 11:13:54,233] INFO [Worker clientId=connect-1, groupId=connect-cluster] Connector mongo-sink-fake-topic-2 config updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1543)
[2022-12-08 11:13:54,238] INFO [Worker clientId=connect-1, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:221)
[2022-12-08 11:13:54,238] INFO [Worker clientId=connect-1, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:540)
[2022-12-08 11:13:54,240] INFO [Worker clientId=connect-1, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=2, memberId='connect-1-959a7585-201e-4793-9430-47c0590d4ddb', protocol='sessioned'} (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:596)
[2022-12-08 11:13:54,245] INFO [Worker clientId=connect-1, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=2, memberId='connect-1-959a7585-201e-4793-9430-47c0590d4ddb', protocol='sessioned'} (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:760)
[2022-12-08 11:13:54,245] INFO [Worker clientId=connect-1, groupId=connect-cluster] Joined group at generation 2 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-1-959a7585-201e-4793-9430-47c0590d4ddb', leaderUrl='http://localhost:8083/', offset=8, connectorIds=[mongo-sink-fake-topic-2, mongo-sink-fake-topic-1], taskIds=[mongo-sink-fake-topic-1-0, mongo-sink-fake-topic-1-1], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1699)
[2022-12-08 11:13:54,245] INFO [Worker clientId=connect-1, groupId=connect-cluster] Starting connectors and tasks using config offset 8 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1244)
[2022-12-08 11:13:54,246] INFO [Worker clientId=connect-1, groupId=connect-cluster] Starting connector mongo-sink-fake-topic-2 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1321)
[2022-12-08 11:13:54,246] INFO Creating connector mongo-sink-fake-topic-2 of type com.mongodb.kafka.connect.MongoSinkConnector (org.apache.kafka.connect.runtime.Worker:271)
[2022-12-08 11:13:54,246] INFO SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = com.mongodb.kafka.connect.MongoSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = mongo-sink-fake-topic-2
	predicates = []
	tasks.max = 2
	topics = [fake-topic-1208]
	topics.regex = 
	transforms = []
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:372)
[2022-12-08 11:13:54,247] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = com.mongodb.kafka.connect.MongoSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = mongo-sink-fake-topic-2
	predicates = []
	tasks.max = 2
	topics = [fake-topic-1208]
	topics.regex = 
	transforms = []
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2022-12-08 11:13:54,247] INFO Instantiated connector mongo-sink-fake-topic-2 with version 1.8.1 of type class com.mongodb.kafka.connect.MongoSinkConnector (org.apache.kafka.connect.runtime.Worker:281)
[2022-12-08 11:13:54,247] INFO Finished creating connector mongo-sink-fake-topic-2 (org.apache.kafka.connect.runtime.Worker:306)
[2022-12-08 11:13:54,247] INFO [Worker clientId=connect-1, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1272)
[2022-12-08 11:13:54,248] INFO SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = com.mongodb.kafka.connect.MongoSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = mongo-sink-fake-topic-2
	predicates = []
	tasks.max = 2
	topics = [fake-topic-1208]
	topics.regex = 
	transforms = []
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:372)
[2022-12-08 11:13:54,248] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = com.mongodb.kafka.connect.MongoSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = mongo-sink-fake-topic-2
	predicates = []
	tasks.max = 2
	topics = [fake-topic-1208]
	topics.regex = 
	transforms = []
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2022-12-08 11:13:54,274] INFO [Worker clientId=connect-1, groupId=connect-cluster] Tasks [mongo-sink-fake-topic-2-0, mongo-sink-fake-topic-2-1] configs updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1558)
[2022-12-08 11:13:54,278] INFO [Worker clientId=connect-1, groupId=connect-cluster] Handling task config update by restarting tasks [] (org.apache.kafka.connect.runtime.distributed.DistributedHerder:674)
[2022-12-08 11:13:54,278] INFO [Worker clientId=connect-1, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:221)
[2022-12-08 11:13:54,278] INFO [Worker clientId=connect-1, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:540)
[2022-12-08 11:13:54,280] INFO [Worker clientId=connect-1, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=3, memberId='connect-1-959a7585-201e-4793-9430-47c0590d4ddb', protocol='sessioned'} (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:596)
[2022-12-08 11:13:54,284] INFO [Worker clientId=connect-1, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=3, memberId='connect-1-959a7585-201e-4793-9430-47c0590d4ddb', protocol='sessioned'} (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:760)
[2022-12-08 11:13:54,285] INFO [Worker clientId=connect-1, groupId=connect-cluster] Joined group at generation 3 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-1-959a7585-201e-4793-9430-47c0590d4ddb', leaderUrl='http://localhost:8083/', offset=11, connectorIds=[mongo-sink-fake-topic-2, mongo-sink-fake-topic-1], taskIds=[mongo-sink-fake-topic-2-0, mongo-sink-fake-topic-2-1, mongo-sink-fake-topic-1-0, mongo-sink-fake-topic-1-1], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1699)
[2022-12-08 11:13:54,285] INFO [Worker clientId=connect-1, groupId=connect-cluster] Starting connectors and tasks using config offset 11 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1244)
[2022-12-08 11:13:54,285] INFO [Worker clientId=connect-1, groupId=connect-cluster] Starting task mongo-sink-fake-topic-2-0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1286)
[2022-12-08 11:13:54,286] INFO [Worker clientId=connect-1, groupId=connect-cluster] Starting task mongo-sink-fake-topic-2-1 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1286)
[2022-12-08 11:13:54,286] INFO Creating task mongo-sink-fake-topic-2-0 (org.apache.kafka.connect.runtime.Worker:505)
[2022-12-08 11:13:54,286] INFO Creating task mongo-sink-fake-topic-2-1 (org.apache.kafka.connect.runtime.Worker:505)
[2022-12-08 11:13:54,286] INFO ConnectorConfig values: 
	config.action.reload = restart
	connector.class = com.mongodb.kafka.connect.MongoSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = mongo-sink-fake-topic-2
	predicates = []
	tasks.max = 2
	transforms = []
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig:372)
[2022-12-08 11:13:54,286] INFO ConnectorConfig values: 
	config.action.reload = restart
	connector.class = com.mongodb.kafka.connect.MongoSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = mongo-sink-fake-topic-2
	predicates = []
	tasks.max = 2
	transforms = []
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig:372)
[2022-12-08 11:13:54,286] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = com.mongodb.kafka.connect.MongoSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = mongo-sink-fake-topic-2
	predicates = []
	tasks.max = 2
	transforms = []
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2022-12-08 11:13:54,287] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = com.mongodb.kafka.connect.MongoSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = mongo-sink-fake-topic-2
	predicates = []
	tasks.max = 2
	transforms = []
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2022-12-08 11:13:54,287] INFO TaskConfig values: 
	task.class = class com.mongodb.kafka.connect.sink.MongoSinkTask
 (org.apache.kafka.connect.runtime.TaskConfig:372)
[2022-12-08 11:13:54,287] INFO TaskConfig values: 
	task.class = class com.mongodb.kafka.connect.sink.MongoSinkTask
 (org.apache.kafka.connect.runtime.TaskConfig:372)
[2022-12-08 11:13:54,287] INFO Instantiated task mongo-sink-fake-topic-2-1 with version 1.8.1 of type com.mongodb.kafka.connect.sink.MongoSinkTask (org.apache.kafka.connect.runtime.Worker:520)
[2022-12-08 11:13:54,287] INFO Instantiated task mongo-sink-fake-topic-2-0 with version 1.8.1 of type com.mongodb.kafka.connect.sink.MongoSinkTask (org.apache.kafka.connect.runtime.Worker:520)
[2022-12-08 11:13:54,288] INFO StringConverterConfig values: 
	converter.encoding = UTF8
	converter.type = key
 (org.apache.kafka.connect.storage.StringConverterConfig:372)
[2022-12-08 11:13:54,288] INFO StringConverterConfig values: 
	converter.encoding = UTF8
	converter.type = key
 (org.apache.kafka.connect.storage.StringConverterConfig:372)
[2022-12-08 11:13:54,288] INFO JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:372)
[2022-12-08 11:13:54,288] INFO JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = false
 (org.apache.kafka.connect.json.JsonConverterConfig:372)
[2022-12-08 11:13:54,288] INFO Set up the key converter class org.apache.kafka.connect.storage.StringConverter for task mongo-sink-fake-topic-2-1 using the connector config (org.apache.kafka.connect.runtime.Worker:535)
[2022-12-08 11:13:54,288] INFO Set up the key converter class org.apache.kafka.connect.storage.StringConverter for task mongo-sink-fake-topic-2-0 using the connector config (org.apache.kafka.connect.runtime.Worker:535)
[2022-12-08 11:13:54,288] INFO Set up the value converter class org.apache.kafka.connect.json.JsonConverter for task mongo-sink-fake-topic-2-1 using the connector config (org.apache.kafka.connect.runtime.Worker:541)
[2022-12-08 11:13:54,288] INFO Set up the value converter class org.apache.kafka.connect.json.JsonConverter for task mongo-sink-fake-topic-2-0 using the connector config (org.apache.kafka.connect.runtime.Worker:541)
[2022-12-08 11:13:54,288] INFO Set up the header converter class org.apache.kafka.connect.storage.SimpleHeaderConverter for task mongo-sink-fake-topic-2-1 using the worker config (org.apache.kafka.connect.runtime.Worker:546)
[2022-12-08 11:13:54,288] INFO Set up the header converter class org.apache.kafka.connect.storage.SimpleHeaderConverter for task mongo-sink-fake-topic-2-0 using the worker config (org.apache.kafka.connect.runtime.Worker:546)
[2022-12-08 11:13:54,289] INFO Initializing: org.apache.kafka.connect.runtime.TransformationChain{} (org.apache.kafka.connect.runtime.Worker:626)
[2022-12-08 11:13:54,289] INFO Initializing: org.apache.kafka.connect.runtime.TransformationChain{} (org.apache.kafka.connect.runtime.Worker:626)
[2022-12-08 11:13:54,289] INFO SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = com.mongodb.kafka.connect.MongoSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = mongo-sink-fake-topic-2
	predicates = []
	tasks.max = 2
	topics = [fake-topic-1208]
	topics.regex = 
	transforms = []
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:372)
[2022-12-08 11:13:54,289] INFO SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = com.mongodb.kafka.connect.MongoSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = mongo-sink-fake-topic-2
	predicates = []
	tasks.max = 2
	topics = [fake-topic-1208]
	topics.regex = 
	transforms = []
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:372)
[2022-12-08 11:13:54,289] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = com.mongodb.kafka.connect.MongoSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = mongo-sink-fake-topic-2
	predicates = []
	tasks.max = 2
	topics = [fake-topic-1208]
	topics.regex = 
	transforms = []
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2022-12-08 11:13:54,290] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = com.mongodb.kafka.connect.MongoSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = class org.apache.kafka.connect.storage.StringConverter
	name = mongo-sink-fake-topic-2
	predicates = []
	tasks.max = 2
	topics = [fake-topic-1208]
	topics.regex = 
	transforms = []
	value.converter = class org.apache.kafka.connect.json.JsonConverter
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:372)
[2022-12-08 11:13:54,290] INFO ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:29092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = connector-consumer-mongo-sink-fake-topic-2-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-mongo-sink-fake-topic-2
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:372)
[2022-12-08 11:13:54,290] INFO ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:29092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = connector-consumer-mongo-sink-fake-topic-2-0
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-mongo-sink-fake-topic-2
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.2
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:372)
[2022-12-08 11:13:54,294] WARN The configuration 'metrics.context.connect.kafka.cluster.id' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:380)
[2022-12-08 11:13:54,294] WARN The configuration 'metrics.context.connect.group.id' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:380)
[2022-12-08 11:13:54,294] WARN The configuration 'metrics.context.connect.kafka.cluster.id' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:380)
[2022-12-08 11:13:54,294] INFO Kafka version: 2.8.2 (org.apache.kafka.common.utils.AppInfoParser:119)
[2022-12-08 11:13:54,294] WARN The configuration 'metrics.context.connect.group.id' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:380)
[2022-12-08 11:13:54,294] INFO Kafka commitId: 3146c6ff4a24cc24 (org.apache.kafka.common.utils.AppInfoParser:120)
[2022-12-08 11:13:54,295] INFO Kafka startTimeMs: 1670465634294 (org.apache.kafka.common.utils.AppInfoParser:121)
[2022-12-08 11:13:54,295] INFO Kafka version: 2.8.2 (org.apache.kafka.common.utils.AppInfoParser:119)
[2022-12-08 11:13:54,295] INFO Kafka commitId: 3146c6ff4a24cc24 (org.apache.kafka.common.utils.AppInfoParser:120)
[2022-12-08 11:13:54,295] INFO Kafka startTimeMs: 1670465634294 (org.apache.kafka.common.utils.AppInfoParser:121)
[2022-12-08 11:13:54,296] INFO [Worker clientId=connect-1, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1272)
[2022-12-08 11:13:54,296] INFO [Consumer clientId=connector-consumer-mongo-sink-fake-topic-2-0, groupId=connect-mongo-sink-fake-topic-2] Subscribed to topic(s): fake-topic-1208 (org.apache.kafka.clients.consumer.KafkaConsumer:965)
[2022-12-08 11:13:54,297] INFO [Consumer clientId=connector-consumer-mongo-sink-fake-topic-2-1, groupId=connect-mongo-sink-fake-topic-2] Subscribed to topic(s): fake-topic-1208 (org.apache.kafka.clients.consumer.KafkaConsumer:965)
[2022-12-08 11:13:54,297] INFO Starting MongoDB sink task (com.mongodb.kafka.connect.sink.MongoSinkTask:64)
[2022-12-08 11:13:54,297] INFO Starting MongoDB sink task (com.mongodb.kafka.connect.sink.MongoSinkTask:64)
[2022-12-08 11:13:54,299] INFO MongoSinkTopicConfig values: 
	bulk.write.ordered = true
	change.data.capture.handler = 
	collection = 
	database = kafka-1
	delete.on.null.values = false
	document.id.strategy = com.mongodb.kafka.connect.sink.processor.id.strategy.BsonOidStrategy
	document.id.strategy.overwrite.existing = false
	document.id.strategy.partial.key.projection.list = 
	document.id.strategy.partial.key.projection.type = 
	document.id.strategy.partial.value.projection.list = 
	document.id.strategy.partial.value.projection.type = 
	document.id.strategy.uuid.format = string
	errors.log.enable = false
	errors.tolerance = none
	field.renamer.mapping = []
	field.renamer.regexp = []
	key.projection.list = 
	key.projection.type = none
	max.batch.size = 0
	mongo.errors.log.enable = false
	mongo.errors.tolerance = none
	namespace.mapper = com.mongodb.kafka.connect.sink.namespace.mapping.DefaultNamespaceMapper
	namespace.mapper.error.if.invalid = false
	namespace.mapper.key.collection.field = 
	namespace.mapper.key.database.field = 
	namespace.mapper.value.collection.field = 
	namespace.mapper.value.database.field = 
	post.processor.chain = [com.mongodb.kafka.connect.sink.processor.DocumentIdAdder]
	rate.limiting.every.n = 0
	rate.limiting.timeout = 0
	timeseries.expire.after.seconds = 0
	timeseries.granularity = 
	timeseries.metafield = 
	timeseries.timefield = 
	timeseries.timefield.auto.convert = false
	timeseries.timefield.auto.convert.date.format = yyyy-MM-dd[['T'][ ]][HH:mm:ss[[.][SSSSSS][SSS]][ ]VV[ ]'['VV']'][HH:mm:ss[[.][SSSSSS][SSS]][ ]X][HH:mm:ss[[.][SSSSSS][SSS]]]
	timeseries.timefield.auto.convert.locale.language.tag = 
	topic = fake-topic-1208
	value.projection.list = 
	value.projection.type = none
	writemodel.strategy = com.mongodb.kafka.connect.sink.writemodel.strategy.DefaultWriteModelStrategy
 (com.mongodb.kafka.connect.sink.MongoSinkTopicConfig:372)
[2022-12-08 11:13:54,299] INFO MongoSinkTopicConfig values: 
	bulk.write.ordered = true
	change.data.capture.handler = 
	collection = 
	database = kafka-1
	delete.on.null.values = false
	document.id.strategy = com.mongodb.kafka.connect.sink.processor.id.strategy.BsonOidStrategy
	document.id.strategy.overwrite.existing = false
	document.id.strategy.partial.key.projection.list = 
	document.id.strategy.partial.key.projection.type = 
	document.id.strategy.partial.value.projection.list = 
	document.id.strategy.partial.value.projection.type = 
	document.id.strategy.uuid.format = string
	errors.log.enable = false
	errors.tolerance = none
	field.renamer.mapping = []
	field.renamer.regexp = []
	key.projection.list = 
	key.projection.type = none
	max.batch.size = 0
	mongo.errors.log.enable = false
	mongo.errors.tolerance = none
	namespace.mapper = com.mongodb.kafka.connect.sink.namespace.mapping.DefaultNamespaceMapper
	namespace.mapper.error.if.invalid = false
	namespace.mapper.key.collection.field = 
	namespace.mapper.key.database.field = 
	namespace.mapper.value.collection.field = 
	namespace.mapper.value.database.field = 
	post.processor.chain = [com.mongodb.kafka.connect.sink.processor.DocumentIdAdder]
	rate.limiting.every.n = 0
	rate.limiting.timeout = 0
	timeseries.expire.after.seconds = 0
	timeseries.granularity = 
	timeseries.metafield = 
	timeseries.timefield = 
	timeseries.timefield.auto.convert = false
	timeseries.timefield.auto.convert.date.format = yyyy-MM-dd[['T'][ ]][HH:mm:ss[[.][SSSSSS][SSS]][ ]VV[ ]'['VV']'][HH:mm:ss[[.][SSSSSS][SSS]][ ]X][HH:mm:ss[[.][SSSSSS][SSS]]]
	timeseries.timefield.auto.convert.locale.language.tag = 
	topic = fake-topic-1208
	value.projection.list = 
	value.projection.type = none
	writemodel.strategy = com.mongodb.kafka.connect.sink.writemodel.strategy.DefaultWriteModelStrategy
 (com.mongodb.kafka.connect.sink.MongoSinkTopicConfig:372)
[2022-12-08 11:13:54,317] INFO MongoClient with metadata {"driver": {"name": "mongo-java-driver|sync|mongo-kafka|sink", "version": "4.7.2|1.8.1"}, "os": {"type": "Darwin", "name": "Mac OS X", "architecture": "x86_64", "version": "10.16"}, "platform": "Java/Oracle Corporation/1.8.0_152-b16"} created with settings MongoClientSettings{readPreference=primary, writeConcern=WriteConcern{w=null, wTimeout=null ms, journal=null}, retryWrites=true, retryReads=true, readConcern=ReadConcern{level=null}, credential=null, streamFactoryFactory=null, commandListeners=[], codecRegistry=ProvidersCodecRegistry{codecProviders=[ValueCodecProvider{}, BsonValueCodecProvider{}, DBRefCodecProvider{}, DBObjectCodecProvider{}, DocumentCodecProvider{}, IterableCodecProvider{}, MapCodecProvider{}, GeoJsonCodecProvider{}, GridFSFileCodecProvider{}, Jsr310CodecProvider{}, JsonObjectCodecProvider{}, BsonCodecProvider{}, EnumCodecProvider{}, com.mongodb.Jep395RecordCodecProvider@4bd8f76b]}, clusterSettings={hosts=[localhost:27017], srvServiceName=mongodb, mode=SINGLE, requiredClusterType=UNKNOWN, requiredReplicaSetName='null', serverSelector='null', clusterListeners='[]', serverSelectionTimeout='30000 ms', localThreshold='30000 ms'}, socketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=0, receiveBufferSize=0, sendBufferSize=0}, heartbeatSocketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=10000, receiveBufferSize=0, sendBufferSize=0}, connectionPoolSettings=ConnectionPoolSettings{maxSize=100, minSize=0, maxWaitTimeMS=120000, maxConnectionLifeTimeMS=0, maxConnectionIdleTimeMS=0, maintenanceInitialDelayMS=0, maintenanceFrequencyMS=60000, connectionPoolListeners=[], maxConnecting=2}, serverSettings=ServerSettings{heartbeatFrequencyMS=10000, minHeartbeatFrequencyMS=500, serverListeners='[]', serverMonitorListeners='[]'}, sslSettings=SslSettings{enabled=false, invalidHostNameAllowed=false, context=null}, applicationName='null', compressorList=[], uuidRepresentation=UNSPECIFIED, serverApi=null, autoEncryptionSettings=null, contextProvider=null} (org.mongodb.driver.client:71)
[2022-12-08 11:13:54,317] INFO Errant record reporter not configured. (com.mongodb.kafka.connect.sink.MongoSinkTask:129)
[2022-12-08 11:13:54,317] INFO MongoClient with metadata {"driver": {"name": "mongo-java-driver|sync|mongo-kafka|sink", "version": "4.7.2|1.8.1"}, "os": {"type": "Darwin", "name": "Mac OS X", "architecture": "x86_64", "version": "10.16"}, "platform": "Java/Oracle Corporation/1.8.0_152-b16"} created with settings MongoClientSettings{readPreference=primary, writeConcern=WriteConcern{w=null, wTimeout=null ms, journal=null}, retryWrites=true, retryReads=true, readConcern=ReadConcern{level=null}, credential=null, streamFactoryFactory=null, commandListeners=[], codecRegistry=ProvidersCodecRegistry{codecProviders=[ValueCodecProvider{}, BsonValueCodecProvider{}, DBRefCodecProvider{}, DBObjectCodecProvider{}, DocumentCodecProvider{}, IterableCodecProvider{}, MapCodecProvider{}, GeoJsonCodecProvider{}, GridFSFileCodecProvider{}, Jsr310CodecProvider{}, JsonObjectCodecProvider{}, BsonCodecProvider{}, EnumCodecProvider{}, com.mongodb.Jep395RecordCodecProvider@4bd8f76b]}, clusterSettings={hosts=[localhost:27017], srvServiceName=mongodb, mode=SINGLE, requiredClusterType=UNKNOWN, requiredReplicaSetName='null', serverSelector='null', clusterListeners='[]', serverSelectionTimeout='30000 ms', localThreshold='30000 ms'}, socketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=0, receiveBufferSize=0, sendBufferSize=0}, heartbeatSocketSettings=SocketSettings{connectTimeoutMS=10000, readTimeoutMS=10000, receiveBufferSize=0, sendBufferSize=0}, connectionPoolSettings=ConnectionPoolSettings{maxSize=100, minSize=0, maxWaitTimeMS=120000, maxConnectionLifeTimeMS=0, maxConnectionIdleTimeMS=0, maintenanceInitialDelayMS=0, maintenanceFrequencyMS=60000, connectionPoolListeners=[], maxConnecting=2}, serverSettings=ServerSettings{heartbeatFrequencyMS=10000, minHeartbeatFrequencyMS=500, serverListeners='[]', serverMonitorListeners='[]'}, sslSettings=SslSettings{enabled=false, invalidHostNameAllowed=false, context=null}, applicationName='null', compressorList=[], uuidRepresentation=UNSPECIFIED, serverApi=null, autoEncryptionSettings=null, contextProvider=null} (org.mongodb.driver.client:71)
[2022-12-08 11:13:54,318] INFO Errant record reporter not configured. (com.mongodb.kafka.connect.sink.MongoSinkTask:129)
[2022-12-08 11:13:54,318] INFO Opened connection [connectionId{localValue:11, serverValue:31}] to localhost:27017 (org.mongodb.driver.connection:71)
[2022-12-08 11:13:54,318] INFO WorkerSinkTask{id=mongo-sink-fake-topic-2-1} Sink task finished initialization and start (org.apache.kafka.connect.runtime.WorkerSinkTask:310)
[2022-12-08 11:13:54,318] INFO Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=13, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=1034398} (org.mongodb.driver.cluster:71)
[2022-12-08 11:13:54,318] INFO Opened connection [connectionId{localValue:10, serverValue:30}] to localhost:27017 (org.mongodb.driver.connection:71)
[2022-12-08 11:13:54,318] INFO Opened connection [connectionId{localValue:9, serverValue:29}] to localhost:27017 (org.mongodb.driver.connection:71)
[2022-12-08 11:13:54,318] INFO Opened connection [connectionId{localValue:12, serverValue:32}] to localhost:27017 (org.mongodb.driver.connection:71)
[2022-12-08 11:13:54,319] INFO Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=13, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=1326810} (org.mongodb.driver.cluster:71)
[2022-12-08 11:13:54,319] INFO WorkerSinkTask{id=mongo-sink-fake-topic-2-1} Executing sink task (org.apache.kafka.connect.runtime.WorkerSinkTask:196)
[2022-12-08 11:13:54,319] WARN MBean name conflict com.mongodb.kafka.connect:type=sink-task-metrics,task=sink-task-2 (com.mongodb.kafka.connect.util.jmx.internal.MBeanServerUtils:75)
javax.management.InstanceAlreadyExistsException: com.mongodb.kafka.connect:type=sink-task-metrics,task=sink-task-2
	at com.sun.jmx.mbeanserver.Repository.addMBean(Repository.java:437)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerWithRepository(DefaultMBeanServerInterceptor.java:1898)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerDynamicMBean(DefaultMBeanServerInterceptor.java:966)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerObject(DefaultMBeanServerInterceptor.java:900)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBean(DefaultMBeanServerInterceptor.java:324)
	at com.sun.jmx.mbeanserver.JmxMBeanServer.registerMBean(JmxMBeanServer.java:522)
	at com.mongodb.kafka.connect.util.jmx.internal.MBeanServerUtils.registerMBean(MBeanServerUtils.java:72)
	at com.mongodb.kafka.connect.util.jmx.internal.MongoMBean.register(MongoMBean.java:151)
	at com.mongodb.kafka.connect.sink.StartedMongoSinkTask.<init>(StartedMongoSinkTask.java:72)
	at com.mongodb.kafka.connect.sink.MongoSinkTask.start(MongoSinkTask.java:72)
	at org.apache.kafka.connect.runtime.WorkerSinkTask.initializeAndStart(WorkerSinkTask.java:309)
	at org.apache.kafka.connect.runtime.WorkerTask.doRun(WorkerTask.java:186)
	at org.apache.kafka.connect.runtime.WorkerTask.run(WorkerTask.java:237)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
[2022-12-08 11:13:54,320] INFO WorkerSinkTask{id=mongo-sink-fake-topic-2-0} Sink task finished initialization and start (org.apache.kafka.connect.runtime.WorkerSinkTask:310)
[2022-12-08 11:13:54,321] INFO WorkerSinkTask{id=mongo-sink-fake-topic-2-0} Executing sink task (org.apache.kafka.connect.runtime.WorkerSinkTask:196)
[2022-12-08 11:13:54,326] INFO [Consumer clientId=connector-consumer-mongo-sink-fake-topic-2-0, groupId=connect-mongo-sink-fake-topic-2] Resetting the last seen epoch of partition fake-topic-1208-0 to 0 since the associated topicId changed from null to VTQtF8PeRR6zv5-DUyP4Lg (org.apache.kafka.clients.Metadata:401)
[2022-12-08 11:13:54,326] INFO [Consumer clientId=connector-consumer-mongo-sink-fake-topic-2-1, groupId=connect-mongo-sink-fake-topic-2] Resetting the last seen epoch of partition fake-topic-1208-0 to 0 since the associated topicId changed from null to VTQtF8PeRR6zv5-DUyP4Lg (org.apache.kafka.clients.Metadata:401)
[2022-12-08 11:13:54,326] INFO [Consumer clientId=connector-consumer-mongo-sink-fake-topic-2-0, groupId=connect-mongo-sink-fake-topic-2] Cluster ID: AJw0mIIBTzmvGtlyebvsaQ (org.apache.kafka.clients.Metadata:287)
[2022-12-08 11:13:54,326] INFO [Consumer clientId=connector-consumer-mongo-sink-fake-topic-2-1, groupId=connect-mongo-sink-fake-topic-2] Cluster ID: AJw0mIIBTzmvGtlyebvsaQ (org.apache.kafka.clients.Metadata:287)
[2022-12-08 11:13:54,326] INFO [Consumer clientId=connector-consumer-mongo-sink-fake-topic-2-0, groupId=connect-mongo-sink-fake-topic-2] Discovered group coordinator localhost:49092 (id: 2147483644 rack: null) (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:850)
[2022-12-08 11:13:54,327] INFO [Consumer clientId=connector-consumer-mongo-sink-fake-topic-2-0, groupId=connect-mongo-sink-fake-topic-2] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:540)
[2022-12-08 11:13:54,328] INFO [Consumer clientId=connector-consumer-mongo-sink-fake-topic-2-1, groupId=connect-mongo-sink-fake-topic-2] Discovered group coordinator localhost:49092 (id: 2147483644 rack: null) (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:850)
[2022-12-08 11:13:54,328] INFO [Consumer clientId=connector-consumer-mongo-sink-fake-topic-2-1, groupId=connect-mongo-sink-fake-topic-2] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:540)
[2022-12-08 11:13:54,332] INFO [Consumer clientId=connector-consumer-mongo-sink-fake-topic-2-0, groupId=connect-mongo-sink-fake-topic-2] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:540)
[2022-12-08 11:13:54,333] INFO [Consumer clientId=connector-consumer-mongo-sink-fake-topic-2-1, groupId=connect-mongo-sink-fake-topic-2] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:540)
[2022-12-08 11:14:00,336] INFO [Consumer clientId=connector-consumer-mongo-sink-fake-topic-2-0, groupId=connect-mongo-sink-fake-topic-2] Successfully joined group with generation Generation{generationId=1, memberId='connector-consumer-mongo-sink-fake-topic-2-0-a14a724a-3650-4e9b-b6af-56a290f965a4', protocol='range'} (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:596)
[2022-12-08 11:14:00,336] INFO [Consumer clientId=connector-consumer-mongo-sink-fake-topic-2-1, groupId=connect-mongo-sink-fake-topic-2] Successfully joined group with generation Generation{generationId=1, memberId='connector-consumer-mongo-sink-fake-topic-2-1-8dc38e6b-a6c6-460e-bc0e-d31a63754453', protocol='range'} (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:596)
[2022-12-08 11:14:00,336] INFO [Consumer clientId=connector-consumer-mongo-sink-fake-topic-2-0, groupId=connect-mongo-sink-fake-topic-2] Finished assignment for group at generation 1: {connector-consumer-mongo-sink-fake-topic-2-1-8dc38e6b-a6c6-460e-bc0e-d31a63754453=Assignment(partitions=[]), connector-consumer-mongo-sink-fake-topic-2-0-a14a724a-3650-4e9b-b6af-56a290f965a4=Assignment(partitions=[fake-topic-1208-0])} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:652)
[2022-12-08 11:14:00,342] INFO [Consumer clientId=connector-consumer-mongo-sink-fake-topic-2-0, groupId=connect-mongo-sink-fake-topic-2] Successfully synced group in generation Generation{generationId=1, memberId='connector-consumer-mongo-sink-fake-topic-2-0-a14a724a-3650-4e9b-b6af-56a290f965a4', protocol='range'} (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:760)
[2022-12-08 11:14:00,342] INFO [Consumer clientId=connector-consumer-mongo-sink-fake-topic-2-0, groupId=connect-mongo-sink-fake-topic-2] Notifying assignor about the new Assignment(partitions=[fake-topic-1208-0]) (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:279)
[2022-12-08 11:14:00,342] INFO [Consumer clientId=connector-consumer-mongo-sink-fake-topic-2-0, groupId=connect-mongo-sink-fake-topic-2] Adding newly assigned partitions: fake-topic-1208-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:291)
[2022-12-08 11:14:00,343] INFO [Consumer clientId=connector-consumer-mongo-sink-fake-topic-2-1, groupId=connect-mongo-sink-fake-topic-2] Successfully synced group in generation Generation{generationId=1, memberId='connector-consumer-mongo-sink-fake-topic-2-1-8dc38e6b-a6c6-460e-bc0e-d31a63754453', protocol='range'} (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:760)
[2022-12-08 11:14:00,343] INFO [Consumer clientId=connector-consumer-mongo-sink-fake-topic-2-1, groupId=connect-mongo-sink-fake-topic-2] Notifying assignor about the new Assignment(partitions=[]) (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:279)
[2022-12-08 11:14:00,343] INFO [Consumer clientId=connector-consumer-mongo-sink-fake-topic-2-1, groupId=connect-mongo-sink-fake-topic-2] Adding newly assigned partitions:  (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:291)
[2022-12-08 11:14:00,344] INFO [Consumer clientId=connector-consumer-mongo-sink-fake-topic-2-0, groupId=connect-mongo-sink-fake-topic-2] Found no committed offset for partition fake-topic-1208-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1388)
[2022-12-08 11:14:00,348] INFO [Consumer clientId=connector-consumer-mongo-sink-fake-topic-2-0, groupId=connect-mongo-sink-fake-topic-2] Resetting offset for partition fake-topic-1208-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:39092 (id: 2 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:398)
[2022-12-08 11:14:00,449] INFO Opened connection [connectionId{localValue:13, serverValue:33}] to localhost:27017 (org.mongodb.driver.connection:71)
